# **ğŸ—ï¸ SpecGovernor è®¾è®¡æ–‡æ¡£ (DD)**

> **ç‰ˆæœ¬**: v1.0
> **åŸºäº**: PRD.md (v1.0) + éœ€æ±‚è¡¥å……-ä»»åŠ¡ç®¡ç†.md (v1.1)
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-16
> **è®¾è®¡ç›®æ ‡**: åŸºäº spec-kit æ¡†æ¶æ„å»º AI å¢å¼ºå‹ç ”å‘æµç¨‹æ²»ç†å·¥å…·

---

## **å¯è¿½æº¯æ€§å£°æ˜**

æœ¬æ–‡æ¡£è®¾è®¡ä»¥ä¸‹ PRD åŠŸèƒ½ï¼š
- [Designs-for: PRD-EPIC-001] é¡¹ç›®åˆå§‹åŒ–
- [Designs-for: PRD-EPIC-002] æ–‡æ¡£ç”Ÿæˆ-è¯„å®¡-ä¿®è®¢å¾ªç¯
- [Designs-for: PRD-EPIC-003] ç´¢å¼•æ„å»ºä¸ä¾èµ–å›¾ç®¡ç†
- [Designs-for: PRD-EPIC-004] å½±å“åˆ†æ
- [Designs-for: PRD-EPIC-005] ä¸€è‡´æ€§æ£€æŸ¥
- [Designs-for: RD-TASK-LAYER-001] ä¸¤å±‚ä»»åŠ¡ç®¡ç†
- [Designs-for: RD-TASK-STATE-001] æ— çŠ¶æ€è§’è‰²è®¾è®¡

---

## **ä¸€ã€ç³»ç»Ÿæ¶æ„**

### **1.1 æ•´ä½“æ¶æ„**

**[ID: DD-ARCH-001]**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SpecGovernor CLI                           â”‚
â”‚                     (åŸºäº spec-kit æ”¹é€ )                          â”‚
â”‚                                                                  â”‚
â”‚  ç”¨æˆ·è¾“å…¥ï¼šspecgov rd:generate --input=user-stories.md          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLI Commands Layer                          â”‚
â”‚                      (å‘½ä»¤å±‚ - ä¸šåŠ¡é€»è¾‘)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  rd:generate  â”‚  rd:review  â”‚  prd:generate  â”‚  index:build  â”‚  â”‚
â”‚  check:consistency  â”‚  analyze:impact  â”‚  tasks:next  â”‚  ...    â”‚
â”‚                                                                  â”‚
â”‚  èŒè´£ï¼šè§£æå‘½ä»¤å‚æ•°ã€åè°ƒå„æ¨¡å—ã€æ§åˆ¶æ‰§è¡Œæµç¨‹                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚              â”‚              â”‚
          â”‚              â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Context   â”‚  â”‚ State  â”‚  â”‚   Core    â”‚  â”‚   Task    â”‚
    â”‚  Builder   â”‚  â”‚ Managerâ”‚  â”‚  Engine   â”‚  â”‚   Mgmt    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ åŠ è½½èƒŒæ™¯  â”‚  â”‚ â€¢ è¯»å–  â”‚  â”‚ â€¢ Tag     â”‚  â”‚ â€¢ Epic    â”‚
    â”‚ â€¢ è£å‰ªæ–‡æ¡£  â”‚  â”‚   çŠ¶æ€  â”‚  â”‚   Parser  â”‚  â”‚   Tracker â”‚
    â”‚ â€¢ æ„å»º     â”‚  â”‚ â€¢ æ›´æ–°  â”‚  â”‚ â€¢ Graph   â”‚  â”‚ â€¢ Role    â”‚
    â”‚   æç¤ºè¯    â”‚  â”‚   è¿›åº¦  â”‚  â”‚   Builder â”‚  â”‚   Tasks   â”‚
    â”‚ â€¢ æ§åˆ¶     â”‚  â”‚ â€¢ è®°å½•  â”‚  â”‚ â€¢ Impact  â”‚  â”‚ â€¢ Compl-  â”‚
    â”‚   å¤§å°     â”‚  â”‚   æˆæœ¬  â”‚  â”‚   Analyzerâ”‚  â”‚   exity   â”‚
    â”‚   <5K      â”‚  â”‚        â”‚  â”‚ â€¢ Consist â”‚  â”‚   Check   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   Checker â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Shared Services             â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚   AI Layer     â”‚   Storage Layer   â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ Generator    â”‚ â€¢ File I/O        â”‚
        â”‚ â€¢ Reviewer     â”‚ â€¢ Git Ops         â”‚
        â”‚ â€¢ AI Backend   â”‚ â€¢ JSON/MD         â”‚
        â”‚   (Claude Code)â”‚   Serializer      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¶æ„è¯´æ˜**ï¼š

1. **CLI Commands Layerï¼ˆå‘½ä»¤å±‚ï¼‰**
   - æ¯ä¸ªå‘½ä»¤ç‹¬ç«‹å®ç°ä¸šåŠ¡é€»è¾‘
   - è´Ÿè´£åè°ƒå„ä¸ªæ¨¡å—å®Œæˆä»»åŠ¡
   - æ— éœ€ç‹¬ç«‹çš„"æµç¨‹ç¼–æ’å™¨"
   - ç›´æ¥è°ƒç”¨ä¸‹å±‚æœåŠ¡

2. **Context Builderï¼ˆä¸Šä¸‹æ–‡æ„å»ºå™¨ï¼‰**
   - åŠ è½½é¡¹ç›®èƒŒæ™¯ï¼ˆproject-brief.mdï¼‰
   - ä»ä¾èµ–å›¾å®šä½ç›¸å…³èŠ‚ç‚¹
   - è£å‰ªæ–‡æ¡£ç‰‡æ®µ
   - æ„å»º AI æç¤ºè¯ï¼ˆ< 5K tokensï¼‰

3. **State Managerï¼ˆçŠ¶æ€ç®¡ç†å™¨ï¼‰**
   - è¯»å†™ `.specgov/state.json`
   - è®°å½•ä»»åŠ¡è¿›åº¦ã€æˆæœ¬ã€æ—¶é—´
   - ç®¡ç†æ–‡æ¡£ç‰ˆæœ¬çŠ¶æ€

4. **Core Engineï¼ˆæ ¸å¿ƒå¼•æ“ï¼‰**
   - Tag Parser: è§£æå¯è¿½æº¯æ€§æ ‡è®°
   - Graph Builder: æ„å»ºä¾èµ–å›¾
   - Impact Analyzer: å½±å“åˆ†æ
   - Consistency Checker: ä¸€è‡´æ€§æ£€æŸ¥

5. **Task Managementï¼ˆä»»åŠ¡ç®¡ç†ï¼‰**
   - Epic Tracker: è·Ÿè¸ªé«˜å±‚ä»»åŠ¡
   - Role Tasks: ç®¡ç†è§’è‰²ä»»åŠ¡
   - Complexity Check: ä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥

---

### **1.2 ä¸ spec-kit çš„å…³ç³»**

**[ID: DD-ARCH-002]**

| spec-kit ç»„ä»¶ | å¤ç”¨ç­–ç•¥ | æ”¹é€ å†…å®¹ |
|--------------|---------|---------|
| **CLI æ¡†æ¶** (Click) | âœ… 100% å¤ç”¨ | æ—  |
| **AI æŠ½è±¡å±‚** | âœ… 80% å¤ç”¨ | æ–°å¢ Generator-Reviewer å¯¹æ¨¡å¼ |
| **æ–‡ä»¶æ“ä½œ** | âœ… 90% å¤ç”¨ | æ–°å¢æ ‡è®°è§£æé€»è¾‘ |
| **é…ç½®ç®¡ç†** | âœ… 70% å¤ç”¨ | æ‰©å±•é…ç½®é¡¹ï¼ˆä»»åŠ¡ç®¡ç†ã€AI åç«¯ï¼‰ |
| **Git é›†æˆ** | âœ… 100% å¤ç”¨ | æ—  |

**æ–°å¢æ¨¡å—ï¼ˆspec-kit æ²¡æœ‰ï¼‰ï¼š**
- æ ‡è®°è§£æå™¨ (Tag Parser)
- ä¾èµ–å›¾å¼•æ“ (Dependency Graph)
- å½±å“åˆ†æå¼•æ“ (Impact Analyzer)
- ä¸€è‡´æ€§æ£€æŸ¥å¼•æ“ (Consistency Checker)
- ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ (Task Management)

---

### **1.3 ç›®å½•ç»“æ„è®¾è®¡**

**[ID: DD-ARCH-003]**

```
specgov/                           # é¡¹ç›®æ ¹ç›®å½•
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/                       # CLI å±‚ï¼ˆå¤ç”¨ spec-kitï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                # ä¸»å…¥å£
â”‚   â”‚   â”œâ”€â”€ commands/              # å‘½ä»¤å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rd.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prd.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dd.py
â”‚   â”‚   â”‚   â”œâ”€â”€ td.py
â”‚   â”‚   â”‚   â”œâ”€â”€ index.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py
â”‚   â”‚   â”‚   â”œâ”€â”€ check.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.py           # æ–°å¢ï¼šä»»åŠ¡ç®¡ç†å‘½ä»¤
â”‚   â”‚   â”‚   â””â”€â”€ role.py            # æ–°å¢ï¼šè§’è‰²åˆ‡æ¢å‘½ä»¤
â”‚   â”‚   â””â”€â”€ ui/
â”‚   â”‚       â”œâ”€â”€ formatter.py       # è¾“å‡ºæ ¼å¼åŒ–
â”‚   â”‚       â””â”€â”€ progress.py        # è¿›åº¦æ˜¾ç¤º
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒå¼•æ“ï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tag_parser.py      # æ ‡è®°è§£æå™¨
â”‚   â”‚   â”‚   â””â”€â”€ tag_types.py       # æ ‡è®°ç±»å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ node.py            # èŠ‚ç‚¹æ•°æ®ç»“æ„
â”‚   â”‚   â”‚   â”œâ”€â”€ edge.py            # è¾¹æ•°æ®ç»“æ„
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py           # ä¾èµ–å›¾
â”‚   â”‚   â”‚   â””â”€â”€ builder.py         # å›¾æ„å»ºå™¨
â”‚   â”‚   â”œâ”€â”€ analyzer/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ impact.py          # å½±å“åˆ†æ
â”‚   â”‚   â”‚   â””â”€â”€ consistency.py     # ä¸€è‡´æ€§æ£€æŸ¥
â”‚   â”‚   â””â”€â”€ index/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ indexer.py         # ç´¢å¼•æ„å»º
â”‚   â”‚       â””â”€â”€ scanner.py         # æ–‡ä»¶æ‰«æ
â”‚   â”‚
â”‚   â”œâ”€â”€ context/                   # ä¸Šä¸‹æ–‡æ„å»ºå™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ builder.py             # Context Builder ä¸»é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ loader.py              # æ–‡æ¡£åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ slicer.py              # æ–‡æ¡£è£å‰ªå™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ state/                     # çŠ¶æ€ç®¡ç†å™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ manager.py             # State Manager ä¸»é€»è¾‘
â”‚   â”‚   â””â”€â”€ state_types.py         # çŠ¶æ€æ•°æ®ç»“æ„
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                     # ä»»åŠ¡ç®¡ç†ç³»ç»Ÿï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ epic.py                # Epic æ•°æ®ç»“æ„
â”‚   â”‚   â”œâ”€â”€ task.py                # Task æ•°æ®ç»“æ„
â”‚   â”‚   â”œâ”€â”€ role.py                # Role å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ complexity.py          # ä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥
â”‚   â”‚   â””â”€â”€ decomposer.py          # ä»»åŠ¡åˆ†è§£å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                        # AI å±‚ï¼ˆå¤ç”¨ + æ‰©å±• spec-kitï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backend.py             # AI åç«¯æŠ½è±¡
â”‚   â”‚   â”œâ”€â”€ claude_code.py         # Claude Code é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ generator.py           # Generator Agent
â”‚   â”‚   â”œâ”€â”€ reviewer.py            # Reviewer Agent
â”‚   â”‚   â””â”€â”€ prompts/               # æç¤ºè¯æ¨¡æ¿
â”‚   â”‚       â”œâ”€â”€ rd_generator.txt
â”‚   â”‚       â”œâ”€â”€ rd_reviewer.txt
â”‚   â”‚       â”œâ”€â”€ prd_generator.txt
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                   # å­˜å‚¨å±‚ï¼ˆå¤ç”¨ spec-kitï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_ops.py            # æ–‡ä»¶æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ git_ops.py             # Git æ“ä½œ
â”‚   â”‚   â””â”€â”€ serializer.py          # JSON/Markdown åºåˆ—åŒ–
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                    # é…ç½®ç®¡ç†ï¼ˆå¤ç”¨ + æ‰©å±•ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # é…ç½®åŠ è½½
â”‚   â”‚   â””â”€â”€ defaults.py            # é»˜è®¤é…ç½®
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°ï¼ˆå¤ç”¨ spec-kitï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ validators.py
â”‚
â”œâ”€â”€ templates/                     # æ¨¡æ¿æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yml.template
â”‚   â”œâ”€â”€ modules.json.template
â”‚   â”œâ”€â”€ rd-review-checklist.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tests/                         # æµ‹è¯•ï¼ˆå¤ç”¨ spec-kit æ¡†æ¶ï¼‰
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ pyproject.toml                 # é¡¹ç›®é…ç½®
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## **äºŒã€æ–°å¢æ¶æ„æ¨¡å—è®¾è®¡**

### **2.1 CLI Commands Layerï¼ˆå‘½ä»¤å±‚ï¼‰**

**[ID: DD-MOD-CLI-001]**

#### **2.1.1 è®¾è®¡åŸåˆ™**

CLI Commands Layer æ˜¯ç”¨æˆ·ä¸ç³»ç»Ÿäº¤äº’çš„å…¥å£ï¼Œæ¯ä¸ªå‘½ä»¤å®ç°ç‹¬ç«‹çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ— éœ€ä¾èµ–"æµç¨‹ç¼–æ’å™¨"ã€‚

**èŒè´£**ï¼š
1. è§£æå‘½ä»¤è¡Œå‚æ•°
2. åè°ƒå„æ¨¡å—å®Œæˆä»»åŠ¡
3. æ§åˆ¶æ‰§è¡Œæµç¨‹
4. è¾“å‡ºç»“æœç»™ç”¨æˆ·

**ç¤ºä¾‹ï¼šrd:generate å‘½ä»¤å®ç°**

```python
# src/cli/commands/rd.py

import click
from ...context.builder import ContextBuilder
from ...state.manager import StateManager
from ...ai.generator import GeneratorAgent
from ...ai.claude_code import ClaudeCodeBackend

@click.group()
def rd():
    """RD é˜¶æ®µå‘½ä»¤"""
    pass

@rd.command()
@click.option('--input', type=click.Path(exists=True), help='è¾“å…¥æ–‡ä»¶')
@click.option('--ai', default='claude-code', help='AI åç«¯')
@click.option('--output', default='docs/RD.md', help='è¾“å‡ºè·¯å¾„')
def generate(input: str, ai: str, output: str):
    """ç”Ÿæˆéœ€æ±‚æ–‡æ¡£ (RD)

    æ‰§è¡Œæµç¨‹ï¼š
    1. CLI Command è¯»å–è¾“å…¥æ–‡ä»¶
    2. è°ƒç”¨ Context Builder æ„å»º AI æç¤ºè¯
    3. è°ƒç”¨ Generator Agent ç”Ÿæˆæ–‡æ¡£
    4. ä¿å­˜ç»“æœ
    5. è°ƒç”¨ State Manager æ›´æ–°çŠ¶æ€
    """
    click.echo("ğŸ¤– RD Generator Agent æ­£åœ¨å·¥ä½œ...")

    # 1. è¯»å–è¾“å…¥ï¼ˆCLI Command çš„èŒè´£ï¼‰
    input_content = ""
    if input:
        click.echo(f"  è¯»å–è¾“å…¥ï¼š{input}")
        with open(input, 'r', encoding='utf-8') as f:
            input_content = f.read()

    # 2. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆè°ƒç”¨ Context Builderï¼‰
    click.echo("  æ„å»º AI ä¸Šä¸‹æ–‡...")
    context_builder = ContextBuilder(project_dir='.')
    prompt = context_builder.build_for_rd_generation(input_content)

    # 3. è°ƒç”¨ AIï¼ˆè°ƒç”¨ Generator Agentï¼‰
    click.echo(f"  è°ƒç”¨ AIï¼š{ai} (claude-sonnet-4)")
    backend = ClaudeCodeBackend()
    generator = GeneratorAgent(backend, stage='rd')
    result = generator.generate(prompt)

    # 4. ä¿å­˜ç»“æœï¼ˆCLI Command çš„èŒè´£ï¼‰
    click.echo("  ä¿å­˜æ–‡æ¡£...")
    output_path = Path(output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(result.content, encoding='utf-8')

    # 5. æ›´æ–°çŠ¶æ€ï¼ˆè°ƒç”¨ State Managerï¼‰
    state_mgr = StateManager(project_dir='.')
    state_mgr.update({
        'rd_generated': True,
        'rd_version': 1,
        'last_generation_time': datetime.now(),
        'tokens_used': result.tokens_input + result.tokens_output,
        'cost': result.cost
    })

    # 6. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    click.echo(f"âœ“ ç”Ÿæˆå®Œæˆï¼š{output}")
    click.echo(f"\nğŸ“Š ç»Ÿè®¡ï¼š")
    click.echo(f"  - ç”Ÿæˆæ—¶é—´ï¼š{result.generation_time}ç§’")
    click.echo(f"  - æˆæœ¬ï¼š${result.cost:.2f}")
    click.echo(f"\nğŸ“š ä¸‹ä¸€æ­¥ï¼š")
    click.echo("  è¿è¡Œ specgov rd:review è¿›è¡Œè¯„å®¡")
```

**å…³é”®ç‚¹**ï¼š
- âœ… å‘½ä»¤è‡ªå·±è´Ÿè´£ä¸šåŠ¡é€»è¾‘
- âœ… è°ƒç”¨å…¶ä»–æ¨¡å—ä½œä¸ºæœåŠ¡
- âœ… æ— éœ€ç‹¬ç«‹çš„"ç¼–æ’å™¨"
- âœ… æ¸…æ™°çš„èŒè´£åˆ’åˆ†

---

### **2.2 Context Builderï¼ˆä¸Šä¸‹æ–‡æ„å»ºå™¨ï¼‰**

**[ID: DD-MOD-CONTEXT-001]**

#### **2.2.1 è®¾è®¡ç›®æ ‡**

Context Builder è´Ÿè´£ä¸º AI Agent æ„å»ºç²¾å‡†çš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ï¼š
1. ä¸Šä¸‹æ–‡å¤§å° < 5K tokens
2. åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
3. è£å‰ªæ— å…³å†…å®¹

#### **2.2.2 æ ¸å¿ƒå®ç°**

```python
# src/context/builder.py

from pathlib import Path
from typing import Dict, List
from ..core.graph.graph import DependencyGraph

class ContextBuilder:
    """ä¸Šä¸‹æ–‡æ„å»ºå™¨

    è´Ÿè´£ï¼š
    1. åŠ è½½é¡¹ç›®èƒŒæ™¯
    2. ä»ä¾èµ–å›¾å®šä½ç›¸å…³èŠ‚ç‚¹
    3. è£å‰ªæ–‡æ¡£ç‰‡æ®µ
    4. æ„å»º AI æç¤ºè¯
    5. æ§åˆ¶ä¸Šä¸‹æ–‡å¤§å° < 5K tokens
    """

    # Token ä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
    CHARS_PER_TOKEN = 4
    MAX_CONTEXT_TOKENS = 5000

    def __init__(self, project_dir: str | Path):
        self.project_dir = Path(project_dir)
        self.context_dir = self.project_dir / '.specgov' / 'context'

    def build_for_rd_generation(self, input_content: str) -> str:
        """ä¸º RD ç”Ÿæˆæ„å»ºä¸Šä¸‹æ–‡"""

        # 1. åŠ è½½é¡¹ç›®ç®€ä»‹ï¼ˆæ°¸ä¹…èƒŒæ™¯ï¼‰
        project_brief = self._load_project_brief()

        # 2. åŠ è½½ RD Generator æç¤ºè¯æ¨¡æ¿
        template = self._load_prompt_template('rd_generator')

        # 3. æ„å»ºå®Œæ•´æç¤ºè¯
        prompt = template.format(
            project_brief=project_brief,
            input_content=input_content
        )

        # 4. æ£€æŸ¥å¹¶è£å‰ªï¼ˆå¦‚æœè¶…å‡ºï¼‰
        prompt = self._ensure_token_limit(prompt)

        return prompt

    def build_for_prd_generation(self, rd_content: str) -> str:
        """ä¸º PRD ç”Ÿæˆæ„å»ºä¸Šä¸‹æ–‡

        éœ€è¦åŠ è½½ï¼š
        1. é¡¹ç›®ç®€ä»‹
        2. RD æ–‡æ¡£ï¼ˆè£å‰ªï¼‰
        3. PRD Generator æç¤ºè¯æ¨¡æ¿
        """

        # 1. åŠ è½½é¡¹ç›®ç®€ä»‹
        project_brief = self._load_project_brief()

        # 2. è£å‰ª RD æ–‡æ¡£ï¼ˆæ™ºèƒ½æå–ç›¸å…³éƒ¨åˆ†ï¼‰
        rd_excerpt = self._extract_relevant_sections(
            rd_content,
            max_tokens=2000  # RD æœ€å¤šå  2K tokens
        )

        # 3. åŠ è½½æç¤ºè¯æ¨¡æ¿
        template = self._load_prompt_template('prd_generator')

        # 4. æ„å»ºæç¤ºè¯
        prompt = template.format(
            project_brief=project_brief,
            rd_content=rd_excerpt
        )

        # 5. æ£€æŸ¥å¹¶è£å‰ª
        prompt = self._ensure_token_limit(prompt)

        return prompt

    def build_for_consistency_check(
        self,
        scope_id: str,
        dependency_graph: DependencyGraph
    ) -> str:
        """ä¸ºä¸€è‡´æ€§æ£€æŸ¥æ„å»ºä¸Šä¸‹æ–‡

        æ­¥éª¤ï¼š
        1. ä»ä¾èµ–å›¾å®šä½ä¾èµ–é“¾
        2. åŠ è½½ä¾èµ–é“¾æ¶‰åŠçš„æ–‡æ¡£å’Œä»£ç 
        3. æ™ºèƒ½è£å‰ªï¼ˆ< 20K tokens for consistency checkï¼‰
        """

        # 1. è·å–ä¾èµ–é“¾
        chain = self._get_dependency_chain(scope_id, dependency_graph)

        # 2. åŠ è½½æ¯ä¸ªèŠ‚ç‚¹çš„å†…å®¹
        context_parts = []
        for node in chain:
            content = self._load_node_content(node)
            context_parts.append(f"## {node.id} ({node.type})\n{content}")

        # 3. åˆå¹¶å¹¶è£å‰ª
        full_context = "\n\n".join(context_parts)
        full_context = self._ensure_token_limit(
            full_context,
            max_tokens=20000  # ä¸€è‡´æ€§æ£€æŸ¥å…è®¸æ›´å¤šä¸Šä¸‹æ–‡
        )

        return full_context

    def _load_project_brief(self) -> str:
        """åŠ è½½é¡¹ç›®ç®€ä»‹"""
        brief_file = self.context_dir / 'project-brief.md'
        if brief_file.exists():
            return brief_file.read_text(encoding='utf-8')
        return ""

    def _load_prompt_template(self, template_name: str) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template_file = Path(__file__).parent.parent / 'ai' / 'prompts' / f'{template_name}.txt'
        return template_file.read_text(encoding='utf-8')

    def _extract_relevant_sections(self, content: str, max_tokens: int) -> str:
        """æ™ºèƒ½æå–ç›¸å…³ç« èŠ‚

        ç­–ç•¥ï¼š
        1. ä¿ç•™æ ‡é¢˜å’Œç¬¬ä¸€æ®µ
        2. ä¿ç•™æ‰€æœ‰å¯è¿½æº¯æ€§æ ‡è®°
        3. è£å‰ªè¯¦ç»†æè¿°
        """
        # ç®€åŒ–å®ç°ï¼šç›´æ¥æˆªæ–­
        max_chars = max_tokens * self.CHARS_PER_TOKEN
        if len(content) > max_chars:
            return content[:max_chars] + "\n\n[... å†…å®¹å·²è£å‰ª ...]"
        return content

    def _ensure_token_limit(self, text: str, max_tokens: int = None) -> str:
        """ç¡®ä¿æ–‡æœ¬ä¸è¶…è¿‡ token é™åˆ¶"""
        if max_tokens is None:
            max_tokens = self.MAX_CONTEXT_TOKENS

        max_chars = max_tokens * self.CHARS_PER_TOKEN
        if len(text) > max_chars:
            return text[:max_chars] + "\n\n[... ä¸Šä¸‹æ–‡å·²è‡ªåŠ¨è£å‰ªä»¥é€‚åº” AI çª—å£ ...]"
        return text

    def _get_dependency_chain(
        self,
        scope_id: str,
        graph: DependencyGraph
    ) -> List:
        """ä»ä¾èµ–å›¾è·å–ä¾èµ–é“¾"""
        # ä½¿ç”¨ä¾èµ–å›¾çš„æ–¹æ³•è·å–ä¸Šæ¸¸å’Œä¸‹æ¸¸èŠ‚ç‚¹
        upstream = graph.get_upstream_nodes(scope_id)
        downstream = graph.get_downstream_nodes(scope_id)
        current = [graph.nodes[scope_id]]
        return list(upstream) + current + list(downstream)
```

**å…³é”®ç‚¹**ï¼š
- âœ… ç‹¬ç«‹çš„æœåŠ¡æ¨¡å—
- âœ… è´Ÿè´£æ‰€æœ‰ä¸Šä¸‹æ–‡è£å‰ªé€»è¾‘
- âœ… ç¡®ä¿ AI è°ƒç”¨çš„ä¸Šä¸‹æ–‡å¤§å°åœ¨é™åˆ¶å†…
- âœ… å¯è¢«ä»»ä½• CLI Command è°ƒç”¨

---

### **2.3 State Managerï¼ˆçŠ¶æ€ç®¡ç†å™¨ï¼‰**

**[ID: DD-MOD-STATE-001]**

#### **2.3.1 è®¾è®¡ç›®æ ‡**

State Manager è´Ÿè´£ç®¡ç†ç³»ç»Ÿçš„æ‰€æœ‰çŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
1. æµç¨‹çŠ¶æ€ï¼ˆRD æ˜¯å¦å·²ç”Ÿæˆï¼‰
2. æ–‡æ¡£ç‰ˆæœ¬
3. ä»»åŠ¡è¿›åº¦
4. æˆæœ¬å’Œæ—¶é—´ç»Ÿè®¡

#### **2.3.2 æ ¸å¿ƒå®ç°**

```python
# src/state/manager.py

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

class StateManager:
    """çŠ¶æ€ç®¡ç†å™¨

    è´Ÿè´£ï¼š
    1. è¯»å†™ .specgov/state.json
    2. è®°å½•ä»»åŠ¡è¿›åº¦
    3. è®°å½•æˆæœ¬å’Œæ—¶é—´
    4. ç®¡ç†æ–‡æ¡£ç‰ˆæœ¬çŠ¶æ€
    """

    def __init__(self, project_dir: str | Path):
        self.project_dir = Path(project_dir)
        self.state_file = self.project_dir / '.specgov' / 'state.json'
        self.state_file.parent.mkdir(parents=True, exist_ok=True)

    def get_state(self) -> Dict[str, Any]:
        """è¯»å–å½“å‰çŠ¶æ€"""
        if not self.state_file.exists():
            return self._default_state()

        try:
            with open(self.state_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Warning: Could not load state: {e}")
            return self._default_state()

    def update(self, updates: Dict[str, Any]):
        """æ›´æ–°çŠ¶æ€"""
        state = self.get_state()
        state.update(updates)
        state['last_update'] = datetime.now().isoformat()

        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)

    def can_generate_prd(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç”Ÿæˆ PRDï¼ˆRD å¿…é¡»å·²ç”Ÿæˆï¼‰"""
        state = self.get_state()
        return state.get('rd_generated', False)

    def can_generate_dd(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç”Ÿæˆ DDï¼ˆPRD å¿…é¡»å·²ç”Ÿæˆï¼‰"""
        state = self.get_state()
        return state.get('prd_generated', False)

    def record_generation(
        self,
        stage: str,
        cost: float,
        tokens: int,
        time_seconds: float
    ):
        """è®°å½•ç”Ÿæˆæ“ä½œçš„ç»Ÿè®¡ä¿¡æ¯"""
        state = self.get_state()

        # æ›´æ–°é˜¶æ®µçŠ¶æ€
        state[f'{stage}_generated'] = True
        state[f'{stage}_version'] = state.get(f'{stage}_version', 0) + 1
        state[f'{stage}_last_generation'] = datetime.now().isoformat()

        # ç´¯è®¡ç»Ÿè®¡
        state['total_cost'] = state.get('total_cost', 0) + cost
        state['total_tokens'] = state.get('total_tokens', 0) + tokens
        state['total_time_seconds'] = state.get('total_time_seconds', 0) + time_seconds

        self.update(state)

    def _default_state(self) -> Dict[str, Any]:
        """é»˜è®¤çŠ¶æ€"""
        return {
            'version': '1.0',
            'created_at': datetime.now().isoformat(),
            'rd_generated': False,
            'prd_generated': False,
            'dd_generated': False,
            'td_generated': False,
            'total_cost': 0.0,
            'total_tokens': 0,
            'total_time_seconds': 0.0
        }
```

**å…³é”®ç‚¹**ï¼š
- âœ… ç®€å•çš„æ–‡ä»¶è¯»å†™
- âœ… æä¾›çŠ¶æ€æŸ¥è¯¢å’Œæ›´æ–°æ¥å£
- âœ… å¯è¢«ä»»ä½• CLI Command è°ƒç”¨
- âœ… æ”¯æŒæµç¨‹éªŒè¯ï¼ˆå¦‚ PRD ç”Ÿæˆå‰å¿…é¡»å…ˆæœ‰ RDï¼‰

---

## **ä¸‰ã€æ ¸å¿ƒå¼•æ“æ¨¡å—è®¾è®¡**

### **3.1 æ ‡è®°è§£æå™¨ (Tag Parser)**

**[ID: DD-MOD-PARSER-001] [Designs-for: PRD-CMD-006]**

#### **3.1.1 æ•°æ®ç»“æ„**

```python
# src/core/parser/tag_types.py

from enum import Enum
from dataclasses import dataclass
from typing import Optional

class TagType(Enum):
    """æ ‡è®°ç±»å‹æšä¸¾"""
    ID = "ID"
    IMPLEMENTS = "Implements"
    DECOMPOSES = "Decomposes"
    DESIGNS_FOR = "Designs-for"
    TESTS_FOR = "Tests-for"

@dataclass
class Tag:
    """æ ‡è®°æ•°æ®ç»“æ„"""
    tag_type: TagType
    target_id: str
    file_path: str
    line_number: int
    context: Optional[str] = None  # æ ‡è®°æ‰€åœ¨çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç« èŠ‚æ ‡é¢˜ï¼‰

    def __str__(self):
        return f"[{self.tag_type.value}: {self.target_id}] at {self.file_path}#{self.line_number}"

@dataclass
class ParseResult:
    """è§£æç»“æœ"""
    tags: list[Tag]
    errors: list[str]
    warnings: list[str]
    file_path: str
    parse_time_ms: float
```

#### **2.1.2 æ ¸å¿ƒå®ç°**

```python
# src/core/parser/tag_parser.py

import re
from pathlib import Path
from typing import List, Optional
from .tag_types import Tag, TagType, ParseResult

class TagParser:
    """æ ‡è®°è§£æå™¨

    è´Ÿè´£ä» Markdown å’Œä»£ç æ–‡ä»¶ä¸­è§£æå¯è¿½æº¯æ€§æ ‡è®°
    """

    # æ­£åˆ™è¡¨è¾¾å¼ï¼šåŒ¹é… [TagType: ID]
    TAG_REGEX = re.compile(
        r'\[(ID|Implements|Decomposes|Designs-for|Tests-for):\s*([\w\-\.]+)\]',
        re.IGNORECASE
    )

    # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
    SUPPORTED_EXTENSIONS = {
        '.md', '.markdown',           # Markdown
        '.py', '.js', '.ts', '.tsx',  # ä»£ç 
        '.java', '.go', '.rs',
        '.cpp', '.c', '.h'
    }

    def __init__(self):
        self.current_context = None

    def parse_file(self, file_path: str | Path) -> ParseResult:
        """è§£æå•ä¸ªæ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            ParseResult: è§£æç»“æœ
        """
        import time
        start = time.time()

        file_path = Path(file_path)
        tags = []
        errors = []
        warnings = []

        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if file_path.suffix not in self.SUPPORTED_EXTENSIONS:
                warnings.append(f"Unsupported file type: {file_path.suffix}")
                return ParseResult([], errors, warnings, str(file_path), 0)

            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            # é€è¡Œè§£æ
            for line_num, line in enumerate(lines, start=1):
                # æ›´æ–°ä¸Šä¸‹æ–‡ï¼ˆMarkdown æ ‡é¢˜ï¼‰
                if file_path.suffix in {'.md', '.markdown'}:
                    if line.startswith('#'):
                        self.current_context = line.strip()

                # æŸ¥æ‰¾æ ‡è®°
                for match in self.TAG_REGEX.finditer(line):
                    tag_type_str, target_id = match.groups()

                    try:
                        tag_type = TagType(tag_type_str)
                        tag = Tag(
                            tag_type=tag_type,
                            target_id=target_id.strip(),
                            file_path=str(file_path),
                            line_number=line_num,
                            context=self.current_context
                        )
                        tags.append(tag)
                    except ValueError:
                        errors.append(f"Invalid tag type '{tag_type_str}' at line {line_num}")

        except FileNotFoundError:
            errors.append(f"File not found: {file_path}")
        except UnicodeDecodeError:
            errors.append(f"File encoding error: {file_path}")
        except Exception as e:
            errors.append(f"Unexpected error: {str(e)}")

        parse_time = (time.time() - start) * 1000
        return ParseResult(tags, errors, warnings, str(file_path), parse_time)

    def parse_directory(self, dir_path: str | Path, exclude_dirs: Optional[List[str]] = None) -> List[ParseResult]:
        """é€’å½’è§£æç›®å½•

        Args:
            dir_path: ç›®å½•è·¯å¾„
            exclude_dirs: æ’é™¤çš„ç›®å½•ï¼ˆå¦‚ node_modules, .gitï¼‰

        Returns:
            List[ParseResult]: æ‰€æœ‰æ–‡ä»¶çš„è§£æç»“æœ
        """
        if exclude_dirs is None:
            exclude_dirs = {'node_modules', '.git', '__pycache__', 'venv', '.venv', 'dist', 'build'}

        dir_path = Path(dir_path)
        results = []

        for file_path in dir_path.rglob('*'):
            # è·³è¿‡ç›®å½•
            if file_path.is_dir():
                continue

            # è·³è¿‡æ’é™¤ç›®å½•ä¸­çš„æ–‡ä»¶
            if any(excluded in file_path.parts for excluded in exclude_dirs):
                continue

            # è§£ææ–‡ä»¶
            if file_path.suffix in self.SUPPORTED_EXTENSIONS:
                result = self.parse_file(file_path)
                results.append(result)

        return results

    def validate_tag_id(self, tag_id: str) -> tuple[bool, Optional[str]]:
        """éªŒè¯æ ‡è®° ID çš„æ ¼å¼

        Args:
            tag_id: æ ‡è®° ID

        Returns:
            (is_valid, error_message)
        """
        # ID æ ¼å¼ï¼šPREFIX-CATEGORY-NUMBER
        # ä¾‹å¦‚ï¼šRD-REQ-005, PRD-FEAT-012
        pattern = r'^[A-Z]+-[A-Z]+-\d+$'

        if re.match(pattern, tag_id):
            return True, None
        else:
            return False, f"Invalid ID format: {tag_id}. Expected: PREFIX-CATEGORY-NUMBER"
```

---

### **2.2 ä¾èµ–å›¾å¼•æ“ (Dependency Graph)**

**[ID: DD-MOD-GRAPH-001] [Designs-for: PRD-US-003.1]**

#### **2.2.1 æ•°æ®ç»“æ„**

```python
# src/core/graph/node.py

from dataclasses import dataclass, field
from enum import Enum
from typing import Optional

class NodeType(Enum):
    """èŠ‚ç‚¹ç±»å‹"""
    REQUIREMENT = "requirement"      # RD
    FEATURE = "feature"              # PRD
    API_DESIGN = "api_design"        # DD
    DATABASE = "database"            # DD
    TEST = "test"                    # TD
    CODE = "code"                    # Code

@dataclass
class Node:
    """ä¾èµ–å›¾èŠ‚ç‚¹"""
    id: str                          # èŠ‚ç‚¹ IDï¼ˆå¦‚ RD-REQ-005ï¼‰
    type: NodeType                   # èŠ‚ç‚¹ç±»å‹
    file_path: str                   # æ‰€åœ¨æ–‡ä»¶è·¯å¾„
    line_number: int                 # è¡Œå·
    context: Optional[str] = None    # ä¸Šä¸‹æ–‡ï¼ˆç« èŠ‚æ ‡é¢˜ï¼‰
    metadata: dict = field(default_factory=dict)  # é¢å¤–å…ƒæ•°æ®

    def __hash__(self):
        return hash(self.id)

    def __eq__(self, other):
        if isinstance(other, Node):
            return self.id == other.id
        return False
```

```python
# src/core/graph/edge.py

from dataclasses import dataclass
from enum import Enum

class EdgeType(Enum):
    """è¾¹ç±»å‹ï¼ˆå¯¹åº”æ ‡è®°ç±»å‹ï¼‰"""
    IMPLEMENTS = "implements"        # A implements B
    DECOMPOSES = "decomposes"        # A decomposes B
    DESIGNS_FOR = "designs_for"      # A designs for B
    TESTS_FOR = "tests_for"          # A tests for B

@dataclass
class Edge:
    """ä¾èµ–å›¾è¾¹"""
    source_id: str                   # æºèŠ‚ç‚¹ ID
    target_id: str                   # ç›®æ ‡èŠ‚ç‚¹ ID
    edge_type: EdgeType              # è¾¹ç±»å‹
    file_path: str                   # è¾¹å®šä¹‰æ‰€åœ¨æ–‡ä»¶
    line_number: int                 # è¡Œå·

    def __str__(self):
        return f"{self.source_id} --[{self.edge_type.value}]--> {self.target_id}"
```

```python
# src/core/graph/graph.py

from typing import Dict, List, Set, Optional
from .node import Node
from .edge import Edge, EdgeType

class DependencyGraph:
    """ä¾èµ–å…³ç³»å›¾

    ä½¿ç”¨é‚»æ¥è¡¨è¡¨ç¤ºçš„æœ‰å‘å›¾
    """

    def __init__(self):
        self.nodes: Dict[str, Node] = {}           # id -> Node
        self.outgoing_edges: Dict[str, List[Edge]] = {}  # source_id -> [Edge]
        self.incoming_edges: Dict[str, List[Edge]] = {}  # target_id -> [Edge]

    def add_node(self, node: Node):
        """æ·»åŠ èŠ‚ç‚¹"""
        if node.id in self.nodes:
            # æ›´æ–°å·²å­˜åœ¨çš„èŠ‚ç‚¹
            self.nodes[node.id] = node
        else:
            self.nodes[node.id] = node
            self.outgoing_edges[node.id] = []
            self.incoming_edges[node.id] = []

    def add_edge(self, edge: Edge):
        """æ·»åŠ è¾¹"""
        # ç¡®ä¿èŠ‚ç‚¹å­˜åœ¨
        if edge.source_id not in self.nodes:
            raise ValueError(f"Source node not found: {edge.source_id}")
        if edge.target_id not in self.nodes:
            raise ValueError(f"Target node not found: {edge.target_id}")

        # æ·»åŠ è¾¹
        self.outgoing_edges[edge.source_id].append(edge)
        self.incoming_edges[edge.target_id].append(edge)

    def get_downstream_nodes(self, node_id: str, max_depth: Optional[int] = None) -> Set[Node]:
        """è·å–ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆä¾èµ–æ­¤èŠ‚ç‚¹çš„æ‰€æœ‰èŠ‚ç‚¹ï¼‰

        Args:
            node_id: èŠ‚ç‚¹ ID
            max_depth: æœ€å¤§æ·±åº¦ï¼ˆNone è¡¨ç¤ºæ— é™ï¼‰

        Returns:
            ä¸‹æ¸¸èŠ‚ç‚¹é›†åˆ
        """
        visited = set()
        queue = [(node_id, 0)]

        while queue:
            current_id, depth = queue.pop(0)

            if current_id in visited:
                continue

            if max_depth is not None and depth > max_depth:
                continue

            visited.add(current_id)

            # æ·»åŠ ä¸‹æ¸¸èŠ‚ç‚¹
            for edge in self.incoming_edges.get(current_id, []):
                queue.append((edge.source_id, depth + 1))

        # ç§»é™¤èµ·å§‹èŠ‚ç‚¹
        visited.discard(node_id)

        return {self.nodes[nid] for nid in visited if nid in self.nodes}

    def get_upstream_nodes(self, node_id: str, max_depth: Optional[int] = None) -> Set[Node]:
        """è·å–ä¸Šæ¸¸èŠ‚ç‚¹ï¼ˆæ­¤èŠ‚ç‚¹ä¾èµ–çš„æ‰€æœ‰èŠ‚ç‚¹ï¼‰"""
        visited = set()
        queue = [(node_id, 0)]

        while queue:
            current_id, depth = queue.pop(0)

            if current_id in visited:
                continue

            if max_depth is not None and depth > max_depth:
                continue

            visited.add(current_id)

            # æ·»åŠ ä¸Šæ¸¸èŠ‚ç‚¹
            for edge in self.outgoing_edges.get(current_id, []):
                queue.append((edge.target_id, depth + 1))

        visited.discard(node_id)
        return {self.nodes[nid] for nid in visited if nid in self.nodes}

    def detect_cycles(self) -> List[List[str]]:
        """æ£€æµ‹å¾ªç¯ä¾èµ–

        Returns:
            å¾ªç¯ä¾èµ–åˆ—è¡¨ï¼Œæ¯ä¸ªå¾ªç¯æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ ID åˆ—è¡¨
        """
        cycles = []
        visited = set()
        rec_stack = set()

        def dfs(node_id: str, path: List[str]) -> bool:
            """æ·±åº¦ä¼˜å…ˆæœç´¢æ£€æµ‹å¾ªç¯"""
            if node_id in rec_stack:
                # å‘ç°å¾ªç¯
                cycle_start = path.index(node_id)
                cycles.append(path[cycle_start:])
                return True

            if node_id in visited:
                return False

            visited.add(node_id)
            rec_stack.add(node_id)
            path.append(node_id)

            for edge in self.outgoing_edges.get(node_id, []):
                dfs(edge.target_id, path[:])

            rec_stack.remove(node_id)
            return False

        for node_id in self.nodes:
            if node_id not in visited:
                dfs(node_id, [])

        return cycles

    def to_json(self) -> dict:
        """åºåˆ—åŒ–ä¸º JSON"""
        return {
            "nodes": [
                {
                    "id": node.id,
                    "type": node.type.value,
                    "file_path": node.file_path,
                    "line_number": node.line_number,
                    "context": node.context,
                    "metadata": node.metadata
                }
                for node in self.nodes.values()
            ],
            "edges": [
                {
                    "source": edge.source_id,
                    "target": edge.target_id,
                    "type": edge.edge_type.value,
                    "file_path": edge.file_path,
                    "line_number": edge.line_number
                }
                for edges in self.outgoing_edges.values()
                for edge in edges
            ]
        }

    @classmethod
    def from_json(cls, data: dict) -> 'DependencyGraph':
        """ä» JSON ååºåˆ—åŒ–"""
        graph = cls()

        # åŠ è½½èŠ‚ç‚¹
        from .node import NodeType
        for node_data in data['nodes']:
            node = Node(
                id=node_data['id'],
                type=NodeType(node_data['type']),
                file_path=node_data['file_path'],
                line_number=node_data['line_number'],
                context=node_data.get('context'),
                metadata=node_data.get('metadata', {})
            )
            graph.add_node(node)

        # åŠ è½½è¾¹
        for edge_data in data['edges']:
            edge = Edge(
                source_id=edge_data['source'],
                target_id=edge_data['target'],
                edge_type=EdgeType(edge_data['type']),
                file_path=edge_data['file_path'],
                line_number=edge_data['line_number']
            )
            graph.add_edge(edge)

        return graph
```

#### **2.2.2 å›¾æ„å»ºå™¨**

```python
# src/core/graph/builder.py

from pathlib import Path
from typing import List
from ..parser.tag_parser import TagParser, ParseResult
from ..parser.tag_types import TagType
from .graph import DependencyGraph
from .node import Node, NodeType
from .edge import Edge, EdgeType

class GraphBuilder:
    """ä¾èµ–å›¾æ„å»ºå™¨"""

    # æ ‡è®°ç±»å‹ -> èŠ‚ç‚¹ç±»å‹æ˜ å°„
    ID_PREFIX_TO_NODE_TYPE = {
        'RD': NodeType.REQUIREMENT,
        'PRD': NodeType.FEATURE,
        'DD': NodeType.API_DESIGN,
        'TD': NodeType.TEST,
        'CODE': NodeType.CODE,
    }

    # æ ‡è®°ç±»å‹ -> è¾¹ç±»å‹æ˜ å°„
    TAG_TO_EDGE_TYPE = {
        TagType.IMPLEMENTS: EdgeType.IMPLEMENTS,
        TagType.DECOMPOSES: EdgeType.DECOMPOSES,
        TagType.DESIGNS_FOR: EdgeType.DESIGNS_FOR,
        TagType.TESTS_FOR: EdgeType.TESTS_FOR,
    }

    def __init__(self):
        self.parser = TagParser()

    def build_from_directory(self, project_dir: str | Path) -> DependencyGraph:
        """ä»é¡¹ç›®ç›®å½•æ„å»ºä¾èµ–å›¾

        Args:
            project_dir: é¡¹ç›®æ ¹ç›®å½•

        Returns:
            DependencyGraph: ä¾èµ–å›¾
        """
        # è§£ææ‰€æœ‰æ–‡ä»¶
        parse_results = self.parser.parse_directory(project_dir)

        # æ„å»ºå›¾
        graph = DependencyGraph()

        # ç¬¬ä¸€æ­¥ï¼šæ·»åŠ æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä» [ID: XXX] æ ‡è®°ï¼‰
        for result in parse_results:
            for tag in result.tags:
                if tag.tag_type == TagType.ID:
                    node = self._create_node_from_tag(tag)
                    graph.add_node(node)

        # ç¬¬äºŒæ­¥ï¼šæ·»åŠ æ‰€æœ‰è¾¹ï¼ˆä» Implements, Decomposes ç­‰æ ‡è®°ï¼‰
        for result in parse_results:
            for tag in result.tags:
                if tag.tag_type != TagType.ID:
                    # æŸ¥æ‰¾æºèŠ‚ç‚¹ï¼ˆåŒä¸€æ–‡ä»¶ä¸­æœ€è¿‘çš„ [ID: XXX]ï¼‰
                    source_node_id = self._find_source_node_id(tag, result)
                    if source_node_id:
                        edge = self._create_edge_from_tag(tag, source_node_id)
                        try:
                            graph.add_edge(edge)
                        except ValueError as e:
                            # ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Š
                            print(f"Warning: {e}")

        return graph

    def _create_node_from_tag(self, tag) -> Node:
        """ä» [ID: XXX] æ ‡è®°åˆ›å»ºèŠ‚ç‚¹"""
        # æ ¹æ® ID å‰ç¼€æ¨æ–­èŠ‚ç‚¹ç±»å‹
        prefix = tag.target_id.split('-')[0]
        node_type = self.ID_PREFIX_TO_NODE_TYPE.get(prefix, NodeType.REQUIREMENT)

        return Node(
            id=tag.target_id,
            type=node_type,
            file_path=tag.file_path,
            line_number=tag.line_number,
            context=tag.context
        )

    def _create_edge_from_tag(self, tag, source_node_id: str) -> Edge:
        """ä» [Implements: XXX] ç­‰æ ‡è®°åˆ›å»ºè¾¹"""
        edge_type = self.TAG_TO_EDGE_TYPE[tag.tag_type]

        return Edge(
            source_id=source_node_id,
            target_id=tag.target_id,
            edge_type=edge_type,
            file_path=tag.file_path,
            line_number=tag.line_number
        )

    def _find_source_node_id(self, tag, parse_result: ParseResult) -> str | None:
        """æŸ¥æ‰¾æºèŠ‚ç‚¹ ID

        è§„åˆ™ï¼šåœ¨åŒä¸€æ–‡ä»¶ä¸­ï¼ŒæŸ¥æ‰¾å½“å‰æ ‡è®°ä¹‹å‰æœ€è¿‘çš„ [ID: XXX] æ ‡è®°
        """
        candidates = [
            t for t in parse_result.tags
            if t.tag_type == TagType.ID and t.line_number < tag.line_number
        ]

        if candidates:
            # è¿”å›æœ€è¿‘çš„
            return max(candidates, key=lambda t: t.line_number).target_id

        return None
```

---

### **2.3 å½±å“åˆ†æå¼•æ“**

**[ID: DD-MOD-ANALYZER-001] [Designs-for: PRD-US-004.1]**

```python
# src/core/analyzer/impact.py

from pathlib import Path
from typing import List, Set
from ..graph.graph import DependencyGraph
from ..graph.node import Node
from ..parser.tag_parser import TagParser
import subprocess

class ImpactAnalyzer:
    """å½±å“åˆ†æå¼•æ“"""

    def __init__(self, graph: DependencyGraph, project_dir: Path):
        self.graph = graph
        self.project_dir = project_dir
        self.parser = TagParser()

    def analyze_file_change(self, changed_file: str | Path) -> dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶å˜æ›´çš„å½±å“

        Args:
            changed_file: å˜æ›´çš„æ–‡ä»¶è·¯å¾„

        Returns:
            å½±å“åˆ†ææŠ¥å‘Šï¼ˆå­—å…¸ï¼‰
        """
        changed_file = Path(changed_file)

        # 1. ä½¿ç”¨ Git diff è·å–å˜æ›´å†…å®¹
        changed_lines = self._get_changed_lines(changed_file)

        # 2. è§£æå˜æ›´æ–‡ä»¶ï¼Œè¯†åˆ«å—å½±å“çš„èŠ‚ç‚¹
        changed_nodes = self._identify_changed_nodes(changed_file, changed_lines)

        # 3. æŸ¥è¯¢ä¾èµ–å›¾ï¼Œè·å–ä¸‹æ¸¸èŠ‚ç‚¹
        affected_nodes = set()
        for node_id in changed_nodes:
            downstream = self.graph.get_downstream_nodes(node_id)
            affected_nodes.update(downstream)

        # 4. åˆ†ç±»å—å½±å“çš„èŠ‚ç‚¹
        affected_docs = [n for n in affected_nodes if n.file_path.endswith('.md')]
        affected_code = [n for n in affected_nodes if not n.file_path.endswith('.md')]

        # 5. ç”Ÿæˆå»ºè®®çš„åç»­æ“ä½œ
        recommendations = self._generate_recommendations(affected_nodes)

        # 6. æ„å»ºæŠ¥å‘Š
        report = {
            "changed_file": str(changed_file),
            "changed_nodes": [
                {
                    "id": nid,
                    "type": self.graph.nodes[nid].type.value,
                    "location": f"{self.graph.nodes[nid].file_path}#{self.graph.nodes[nid].line_number}"
                }
                for nid in changed_nodes
            ],
            "affected_documents": [
                {
                    "id": node.id,
                    "type": node.type.value,
                    "location": f"{node.file_path}#{node.line_number}",
                    "context": node.context
                }
                for node in affected_docs
            ],
            "affected_code": [
                {
                    "id": node.id,
                    "type": node.type.value,
                    "location": f"{node.file_path}#{node.line_number}",
                    "context": node.context
                }
                for node in affected_code
            ],
            "recommendations": recommendations
        }

        return report

    def _get_changed_lines(self, file_path: Path) -> Set[int]:
        """ä½¿ç”¨ Git diff è·å–å˜æ›´çš„è¡Œå·"""
        try:
            # git diff HEAD <file> --unified=0
            result = subprocess.run(
                ['git', 'diff', 'HEAD', str(file_path), '--unified=0'],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )

            # è§£æ diff è¾“å‡ºï¼Œæå–è¡Œå·
            changed_lines = set()
            for line in result.stdout.split('\n'):
                if line.startswith('@@'):
                    # æ ¼å¼ï¼š@@ -old_start,old_count +new_start,new_count @@
                    import re
                    match = re.search(r'\+(\d+),?(\d+)?', line)
                    if match:
                        start = int(match.group(1))
                        count = int(match.group(2)) if match.group(2) else 1
                        changed_lines.update(range(start, start + count))

            return changed_lines
        except Exception as e:
            print(f"Warning: Could not get git diff: {e}")
            return set()

    def _identify_changed_nodes(self, file_path: Path, changed_lines: Set[int]) -> Set[str]:
        """è¯†åˆ«å˜æ›´æ–‡ä»¶ä¸­å—å½±å“çš„èŠ‚ç‚¹"""
        # é‡æ–°è§£ææ–‡ä»¶
        result = self.parser.parse_file(file_path)

        changed_nodes = set()
        for tag in result.tags:
            if tag.tag_type.value == "ID":
                # æ£€æŸ¥æ­¤æ ‡è®°æ˜¯å¦åœ¨å˜æ›´èŒƒå›´å†…
                if tag.line_number in changed_lines:
                    changed_nodes.add(tag.target_id)

        return changed_nodes

    def _generate_recommendations(self, affected_nodes: Set[Node]) -> List[str]:
        """ç”Ÿæˆåç»­æ“ä½œå»ºè®®"""
        recommendations = []

        # åˆ†ç»„
        prd_nodes = [n for n in affected_nodes if n.id.startswith('PRD-')]
        dd_nodes = [n for n in affected_nodes if n.id.startswith('DD-')]
        code_nodes = [n for n in affected_nodes if n.id.startswith('CODE-')]

        if prd_nodes:
            recommendations.append(
                f"é‡æ–°ç”Ÿæˆå—å½±å“çš„ PRD éƒ¨åˆ†: specgov prd:regenerate --scope={prd_nodes[0].id}"
            )

        if dd_nodes:
            recommendations.append(
                f"è¯„å®¡å¹¶æ›´æ–° DD: specgov dd:review --scope={dd_nodes[0].id}"
            )

        if code_nodes:
            recommendations.append(
                f"æ£€æŸ¥ä»£ç ä¸€è‡´æ€§: specgov check:consistency --scope={code_nodes[0].id}"
            )

        return recommendations
```

---

### **2.4 ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ**

**[ID: DD-MOD-TASK-001] [Designs-for: RD-TASK-LAYER-001]**

#### **2.4.1 æ•°æ®ç»“æ„**

```python
# src/tasks/epic.py

from dataclasses import dataclass, field
from enum import Enum
from typing import List, Optional
from datetime import datetime

class EpicStatus(Enum):
    """Epic çŠ¶æ€"""
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    BLOCKED = "blocked"

@dataclass
class Epic:
    """Epicï¼ˆé«˜å±‚çº§ä»»åŠ¡ï¼‰"""
    id: str                          # Epic IDï¼ˆå¦‚ EPIC-RD-001ï¼‰
    title: str                       # Epic æ ‡é¢˜
    status: EpicStatus               # çŠ¶æ€
    role: str                        # è´Ÿè´£è§’è‰²
    subtasks: List[str] = field(default_factory=list)  # å­ä»»åŠ¡ ID åˆ—è¡¨
    completed_subtasks: int = 0      # å·²å®Œæˆå­ä»»åŠ¡æ•°
    total_subtasks: int = 0          # æ€»å­ä»»åŠ¡æ•°
    estimated_time_minutes: int = 0  # é¢„è®¡æ—¶é—´
    actual_time_minutes: int = 0     # å®é™…æ—¶é—´
    deliverables: List[str] = field(default_factory=list)  # äº¤ä»˜ç‰©
    summary: Optional[str] = None    # æ€»ç»“
    created_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    @property
    def progress(self) -> float:
        """è¿›åº¦ç™¾åˆ†æ¯”"""
        if self.total_subtasks == 0:
            return 0.0
        return self.completed_subtasks / self.total_subtasks * 100
```

```python
# src/tasks/task.py

from dataclasses import dataclass, field
from enum import Enum
from typing import List, Optional, Dict
from datetime import datetime

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    BLOCKED = "blocked"

class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦"""
    SIMPLE = "simple"          # < 5K tokens
    MEDIUM = "medium"          # 5K - 10K tokens
    COMPLEX = "complex"        # 10K - 20K tokens
    TOO_COMPLEX = "too_complex"  # > 20K tokens

@dataclass
class Task:
    """è§’è‰²çº§ä»»åŠ¡"""
    id: str                          # ä»»åŠ¡ IDï¼ˆå¦‚ TASK-RD-GEN-001ï¼‰
    epic_id: str                     # æ‰€å± Epic
    title: str                       # ä»»åŠ¡æ ‡é¢˜
    status: TaskStatus               # çŠ¶æ€
    command: str                     # æ‰§è¡Œå‘½ä»¤
    context_files: List[str] = field(default_factory=list)  # ä¸Šä¸‹æ–‡æ–‡ä»¶
    acceptance_criteria: List[str] = field(default_factory=list)  # éªŒæ”¶æ ‡å‡†
    complexity: Optional[TaskComplexity] = None  # ä»»åŠ¡å¤æ‚åº¦
    estimated_tokens: int = 0        # é¢„è®¡ Token æ•°
    ai_backend: str = "claude-code"  # AI åç«¯
    estimated_cost: float = 0.0      # é¢„è®¡æˆæœ¬
    actual_cost: float = 0.0         # å®é™…æˆæœ¬
    estimated_time_minutes: int = 0  # é¢„è®¡æ—¶é—´
    actual_time_minutes: int = 0     # å®é™…æ—¶é—´
    outputs: List[str] = field(default_factory=list)  # è¾“å‡ºæ–‡ä»¶
    created_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
```

```python
# src/tasks/role.py

from enum import Enum

class Role(Enum):
    """è§’è‰²å®šä¹‰"""
    PROJECT_MANAGER = "project-manager"
    RD_ANALYST = "rd-analyst"
    PRODUCT_MANAGER = "product-manager"
    ARCHITECT = "architect"
    TEST_MANAGER = "test-manager"
    DEVELOPER = "developer"

    @property
    def display_name(self) -> str:
        """æ˜¾ç¤ºåç§°"""
        names = {
            Role.PROJECT_MANAGER: "é¡¹ç›®ç»ç†",
            Role.RD_ANALYST: "éœ€æ±‚åˆ†æå¸ˆ",
            Role.PRODUCT_MANAGER: "äº§å“ç»ç†",
            Role.ARCHITECT: "æ¶æ„å¸ˆ",
            Role.TEST_MANAGER: "æµ‹è¯•ç»ç†",
            Role.DEVELOPER: "å¼€å‘å·¥ç¨‹å¸ˆ",
        }
        return names[self]

    @property
    def responsibilities(self) -> str:
        """èŒè´£æè¿°"""
        resp = {
            Role.RD_ANALYST: "åˆ†æä¸šåŠ¡éœ€æ±‚ï¼Œç”Ÿæˆéœ€æ±‚æ–‡æ¡£ (RD)ï¼Œè¯„å®¡éœ€æ±‚çš„å®Œæ•´æ€§å’Œåˆç†æ€§",
            Role.PRODUCT_MANAGER: "åŸºäº RD ç”Ÿæˆäº§å“éœ€æ±‚æ–‡æ¡£ (PRD)ï¼Œå®šä¹‰äº§å“åŠŸèƒ½å’Œç”¨æˆ·æ•…äº‹",
            Role.ARCHITECT: "åŸºäº PRD è®¾è®¡ç³»ç»Ÿæ¶æ„å’ŒæŠ€æœ¯æ–¹æ¡ˆ (DD)ï¼Œå®šä¹‰ API å’Œæ•°æ®ç»“æ„",
            Role.TEST_MANAGER: "åŸºäº DD è®¾è®¡æµ‹è¯•ç­–ç•¥å’Œæµ‹è¯•ç”¨ä¾‹ (TD)ï¼Œç¡®ä¿è´¨é‡è¦†ç›–",
            Role.DEVELOPER: "åŸºäº DD å®ç°ä»£ç ï¼Œç¡®ä¿ç¬¦åˆè®¾è®¡è§„èŒƒ",
            Role.PROJECT_MANAGER: "ç®¡ç†é¡¹ç›®æ•´ä½“è¿›åº¦ï¼Œåè°ƒå„è§’è‰²ï¼Œè·Ÿè¸ª Epic å®Œæˆæƒ…å†µ",
        }
        return resp.get(self, "")

    @property
    def task_file(self) -> str:
        """ä»»åŠ¡æ–‡ä»¶è·¯å¾„"""
        return f".specgov/tasks/{self.value}.md"
```

#### **2.4.2 ä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥å™¨**

```python
# src/tasks/complexity.py

from typing import List, Optional
from pathlib import Path
from .task import Task, TaskComplexity

class ComplexityChecker:
    """ä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥å™¨"""

    # Token ä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
    CHARS_PER_TOKEN = 4

    # å¤æ‚åº¦é˜ˆå€¼
    THRESHOLDS = {
        TaskComplexity.SIMPLE: 5000,
        TaskComplexity.MEDIUM: 10000,
        TaskComplexity.COMPLEX: 20000,
    }

    def check_task(self, task: Task) -> tuple[TaskComplexity, Optional[str]]:
        """æ£€æŸ¥ä»»åŠ¡å¤æ‚åº¦

        Returns:
            (complexity, warning_message)
        """
        # ä¼°ç®—ä¸Šä¸‹æ–‡å¤§å°
        total_tokens = self._estimate_context_size(task)

        # åˆ¤æ–­å¤æ‚åº¦
        if total_tokens > self.THRESHOLDS[TaskComplexity.COMPLEX]:
            return (
                TaskComplexity.TOO_COMPLEX,
                f"ä»»åŠ¡è¿‡äºå¤æ‚ï¼ˆ{total_tokens} tokensï¼‰ï¼Œå»ºè®®åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡"
            )
        elif total_tokens > self.THRESHOLDS[TaskComplexity.MEDIUM]:
            return (
                TaskComplexity.COMPLEX,
                f"ä»»åŠ¡è¾ƒå¤æ‚ï¼ˆ{total_tokens} tokensï¼‰ï¼Œå»ºè®®ä»”ç»†æ£€æŸ¥"
            )
        elif total_tokens > self.THRESHOLDS[TaskComplexity.SIMPLE]:
            return (
                TaskComplexity.MEDIUM,
                None
            )
        else:
            return (
                TaskComplexity.SIMPLE,
                None
            )

    def _estimate_context_size(self, task: Task) -> int:
        """ä¼°ç®—ä»»åŠ¡çš„ä¸Šä¸‹æ–‡å¤§å°ï¼ˆtokensï¼‰"""
        total_chars = 0

        # 1. è§’è‰²å®šä¹‰ + èŒè´£ï¼ˆçº¦ 500 tokensï¼‰
        total_chars += 500 * self.CHARS_PER_TOKEN

        # 2. é¡¹ç›®èƒŒæ™¯ï¼ˆproject-brief.mdï¼Œçº¦ 500 tokensï¼‰
        total_chars += 500 * self.CHARS_PER_TOKEN

        # 3. å½“å‰ç„¦ç‚¹ï¼ˆcurrent-focus.mdï¼Œçº¦ 300 tokensï¼‰
        total_chars += 300 * self.CHARS_PER_TOKEN

        # 4. ä¸Šä¸‹æ–‡æ–‡ä»¶
        for file_path in task.context_files:
            try:
                size = Path(file_path).stat().st_size
                total_chars += size
            except FileNotFoundError:
                pass

        # 5. ä»»åŠ¡æŒ‡ä»¤ï¼ˆçº¦ 200 tokensï¼‰
        total_chars += 200 * self.CHARS_PER_TOKEN

        return total_chars // self.CHARS_PER_TOKEN

    def suggest_decomposition(self, task: Task) -> List[str]:
        """å»ºè®®ä»»åŠ¡åˆ†è§£æ–¹æ¡ˆ

        Returns:
            åˆ†è§£åçš„å­ä»»åŠ¡å»ºè®®
        """
        suggestions = []

        # åŸºäºä»»åŠ¡ç±»å‹çš„åˆ†è§£ç­–ç•¥
        if "generate" in task.command:
            # ç”Ÿæˆä»»åŠ¡ï¼šå»ºè®®æŒ‰æ¨¡å—åˆ†è§£
            suggestions.append("æŒ‰æ¨¡å—åˆ†è§£ï¼š--scope=ModuleName")
            suggestions.append("ä½¿ç”¨è‡ªåŠ¨åˆ†è§£ï¼š--auto-decompose")

        elif "review" in task.command:
            # è¯„å®¡ä»»åŠ¡ï¼šå»ºè®®åˆ†æ®µè¯„å®¡
            suggestions.append("åˆ†æ®µè¯„å®¡ï¼š--section=1")

        elif "check:consistency" in task.command and "--scope=full" in task.command:
            # å…¨é¡¹ç›®æ£€æŸ¥ï¼šå»ºè®®å¹¶è¡Œæ£€æŸ¥
            suggestions.append("å¹¶è¡Œæ£€æŸ¥å„æ¨¡å—")

        return suggestions
```

#### **2.4.3 ä¸Šä¸‹æ–‡ç®¡ç†å™¨**

```python
# src/tasks/context.py

from pathlib import Path
from typing import List, Dict, Optional
import json

class ContextManager:
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    è´Ÿè´£ç®¡ç†å’ŒåŠ è½½ä»»åŠ¡æ‰§è¡Œæ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    """

    def __init__(self, project_dir: Path):
        self.project_dir = project_dir
        self.context_dir = project_dir / '.specgov' / 'context'

    def load_project_brief(self) -> str:
        """åŠ è½½é¡¹ç›®ç®€ä»‹"""
        brief_file = self.context_dir / 'project-brief.md'
        if brief_file.exists():
            return brief_file.read_text(encoding='utf-8')
        return ""

    def load_current_focus(self) -> str:
        """åŠ è½½å½“å‰ç„¦ç‚¹"""
        focus_file = self.context_dir / 'current-focus.md'
        if focus_file.exists():
            return focus_file.read_text(encoding='utf-8')
        return ""

    def update_current_focus(self, content: str):
        """æ›´æ–°å½“å‰ç„¦ç‚¹"""
        focus_file = self.context_dir / 'current-focus.md'
        focus_file.write_text(content, encoding='utf-8')

    def load_roles_context(self) -> Dict:
        """åŠ è½½è§’è‰²ä¸Šä¸‹æ–‡"""
        context_file = self.context_dir / 'roles-context.json'
        if context_file.exists():
            return json.loads(context_file.read_text(encoding='utf-8'))
        return {}

    def update_role_context(self, role: str, context: Dict):
        """æ›´æ–°è§’è‰²ä¸Šä¸‹æ–‡"""
        all_contexts = self.load_roles_context()
        all_contexts[role] = context

        context_file = self.context_dir / 'roles-context.json'
        context_file.write_text(
            json.dumps(all_contexts, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )

    def build_task_prompt(self, role: 'Role', task: 'Task') -> str:
        """æ„å»ºä»»åŠ¡çš„ AI æç¤ºè¯

        Args:
            role: è§’è‰²
            task: ä»»åŠ¡

        Returns:
            å®Œæ•´çš„ AI æç¤ºè¯
        """
        # 1. è§’è‰²å®šä¹‰
        role_prompt = f"""ä½ æ˜¯ä¸€ä½{role.display_name}ã€‚

ä½ çš„èŒè´£ï¼š
{role.responsibilities}
"""

        # 2. é¡¹ç›®èƒŒæ™¯
        background = self.load_project_brief()

        # 3. å½“å‰ç„¦ç‚¹
        focus = self.load_current_focus()

        # 4. ä»»åŠ¡ä¸Šä¸‹æ–‡
        task_context = self._load_task_context(task)

        # 5. ä»»åŠ¡æŒ‡ä»¤
        task_prompt = f"""å½“å‰ä»»åŠ¡ï¼š{task.title}

æ‰§è¡Œå‘½ä»¤ï¼š
{task.command}

éªŒæ”¶æ ‡å‡†ï¼š
{self._format_criteria(task.acceptance_criteria)}
"""

        # 6. ç»„åˆ
        full_prompt = f"""{role_prompt}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é¡¹ç›®èƒŒæ™¯
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{background}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å½“å‰çŠ¶æ€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{focus}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç›¸å…³æ–‡æ¡£
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{task_context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å½“å‰ä»»åŠ¡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{task_prompt}
"""

        return full_prompt

    def _load_task_context(self, task: 'Task') -> str:
        """åŠ è½½ä»»åŠ¡çš„ä¸Šä¸‹æ–‡æ–‡ä»¶"""
        context_parts = []

        for file_path in task.context_files:
            try:
                path = Path(file_path)
                if path.exists():
                    content = path.read_text(encoding='utf-8')
                    # æ™ºèƒ½è£å‰ªï¼šåªåŠ è½½ç›¸å…³éƒ¨åˆ†ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥æ›´æ™ºèƒ½ï¼‰
                    context_parts.append(f"ã€{file_path}ã€‘\n{content[:2000]}")  # é™åˆ¶æ¯ä¸ªæ–‡ä»¶æœ€å¤š2000å­—ç¬¦
            except Exception as e:
                context_parts.append(f"ã€{file_path}ã€‘\næ— æ³•åŠ è½½ï¼š{e}")

        return "\n\n".join(context_parts)

    def _format_criteria(self, criteria: List[str]) -> str:
        """æ ¼å¼åŒ–éªŒæ”¶æ ‡å‡†"""
        if not criteria:
            return "æ— "
        return "\n".join(f"- {c}" for c in criteria)
```

---

## **ä¸‰ã€AI é›†æˆå±‚è®¾è®¡**

### **3.1 AI åç«¯æŠ½è±¡**

**[ID: DD-AI-001] [Designs-for: PRD-TECH-001]**

```python
# src/ai/backend.py

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional

@dataclass
class AIResponse:
    """AI å“åº”"""
    content: str
    tokens_input: int
    tokens_output: int
    cost: float
    model: str
    backend: str

class AIBackend(ABC):
    """AI åç«¯æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def generate(self, prompt: str, max_tokens: int = 4000) -> AIResponse:
        """ç”Ÿæˆå†…å®¹

        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§è¾“å‡º tokens

        Returns:
            AIResponse: AI å“åº”
        """
        pass

    @abstractmethod
    def get_name(self) -> str:
        """è·å–åç«¯åç§°"""
        pass

    @abstractmethod
    def get_model(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        pass
```

```python
# src/ai/claude_code.py

import subprocess
import json
from .backend import AIBackend, AIResponse

class ClaudeCodeBackend(AIBackend):
    """Claude Code åç«¯é€‚é…å™¨"""

    def __init__(self, model: str = "claude-sonnet-4"):
        self.model = model

        # æˆæœ¬ï¼ˆæ¯ 1K tokensï¼‰
        self.cost_per_1k = {
            "input": 0.003,
            "output": 0.015
        }

    def generate(self, prompt: str, max_tokens: int = 4000) -> AIResponse:
        """è°ƒç”¨ Claude Code ç”Ÿæˆå†…å®¹"""

        # è°ƒç”¨ claude-code CLIï¼ˆå‡è®¾æœ‰è¿™æ ·çš„å‘½ä»¤ï¼‰
        # å®é™…å®ç°éœ€è¦æ ¹æ® Claude Code çš„çœŸå® API
        try:
            result = subprocess.run(
                [
                    'claude-code',
                    'execute',
                    '--model', self.model,
                    '--max-tokens', str(max_tokens),
                    '--prompt', prompt
                ],
                capture_output=True,
                text=True,
                timeout=300  # 5 åˆ†é’Ÿè¶…æ—¶
            )

            # è§£æè¾“å‡ºï¼ˆå‡è®¾è¿”å› JSONï¼‰
            output = json.loads(result.stdout)

            # è®¡ç®—æˆæœ¬
            tokens_in = output.get('tokens_input', 0)
            tokens_out = output.get('tokens_output', 0)
            cost = (tokens_in / 1000 * self.cost_per_1k['input'] +
                    tokens_out / 1000 * self.cost_per_1k['output'])

            return AIResponse(
                content=output['content'],
                tokens_input=tokens_in,
                tokens_output=tokens_out,
                cost=cost,
                model=self.model,
                backend='claude-code'
            )

        except Exception as e:
            raise RuntimeError(f"Claude Code execution failed: {e}")

    def get_name(self) -> str:
        return "claude-code"

    def get_model(self) -> str:
        return self.model
```

### **3.2 Generator-Reviewer æ¨¡å¼**

**[ID: DD-AI-002] [Designs-for: PRD-US-002.1]**

```python
# src/ai/generator.py

from pathlib import Path
from .backend import AIBackend

class GeneratorAgent:
    """Generator Agentï¼ˆç”Ÿæˆå™¨ï¼‰"""

    def __init__(self, backend: AIBackend, stage: str):
        self.backend = backend
        self.stage = stage  # rd, prd, dd, td
        self.prompt_template = self._load_prompt_template()

    def generate(self, input_data: dict) -> str:
        """ç”Ÿæˆæ–‡æ¡£

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼ˆä¾èµ–ä¸Šæ¸¸æ–‡æ¡£ã€ç”¨æˆ·è¾“å…¥ç­‰ï¼‰

        Returns:
            ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹
        """
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(input_data)

        # è°ƒç”¨ AI
        response = self.backend.generate(prompt)

        return response.content

    def _load_prompt_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template_file = Path(__file__).parent / 'prompts' / f'{self.stage}_generator.txt'
        if template_file.exists():
            return template_file.read_text(encoding='utf-8')
        return self._default_prompt_template()

    def _build_prompt(self, input_data: dict) -> str:
        """æ„å»ºæç¤ºè¯"""
        # å¡«å……æ¨¡æ¿
        prompt = self.prompt_template.format(**input_data)
        return prompt

    def _default_prompt_template(self) -> str:
        """é»˜è®¤æç¤ºè¯æ¨¡æ¿"""
        return f"""ä½ æ˜¯ä¸€ä½{self.stage.upper()}æ–‡æ¡£ç”Ÿæˆä¸“å®¶ã€‚

ã€é‡è¦è¦æ±‚ã€‘
1. ä¸ºæ¯ä¸ªéœ€æ±‚/åŠŸèƒ½åˆ†é…å”¯ä¸€ IDï¼š[ID: {self.stage.upper()}-XXX-YYY]
2. ä½¿ç”¨ [Implements: XXX] æ ‡è®°å®ç°å…³ç³»
3. è¾“å‡º Markdown æ ¼å¼

è¾“å…¥å†…å®¹ï¼š
{{input_content}}

è¯·ç”Ÿæˆè§„èŒƒçš„æ–‡æ¡£ã€‚
"""
```

```python
# src/ai/reviewer.py

from .backend import AIBackend
import json

class ReviewerAgent:
    """Reviewer Agentï¼ˆè¯„å®¡å™¨ï¼‰"""

    def __init__(self, backend: AIBackend, stage: str):
        self.backend = backend
        self.stage = stage
        self.prompt_template = self._load_prompt_template()

    def review(self, document_content: str) -> dict:
        """è¯„å®¡æ–‡æ¡£

        Args:
            document_content: æ–‡æ¡£å†…å®¹

        Returns:
            è¯„å®¡æŠ¥å‘Šï¼ˆå­—å…¸ï¼‰
        """
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(document_content)

        # è°ƒç”¨ AI
        response = self.backend.generate(prompt)

        # è§£æè¯„å®¡æŠ¥å‘Šï¼ˆå‡è®¾ AI è¿”å› JSONï¼‰
        try:
            report = json.loads(response.content)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯ JSONï¼Œå°è¯•è§£æ Markdown
            report = self._parse_markdown_review(response.content)

        return report

    def _load_prompt_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template_file = Path(__file__).parent / 'prompts' / f'{self.stage}_reviewer.txt'
        if template_file.exists():
            return template_file.read_text(encoding='utf-8')
        return self._default_prompt_template()

    def _build_prompt(self, document_content: str) -> str:
        """æ„å»ºæç¤ºè¯"""
        prompt = self.prompt_template.format(document=document_content)
        return prompt

    def _default_prompt_template(self) -> str:
        """é»˜è®¤æç¤ºè¯æ¨¡æ¿"""
        return f"""ä½ æ˜¯ä¸€ä½{self.stage.upper()}æ–‡æ¡£è¯„å®¡ä¸“å®¶ã€‚

è¯·è¯„å®¡ä»¥ä¸‹æ–‡æ¡£ï¼Œæ£€æŸ¥ï¼š
1. å¯è¿½æº¯æ€§æ ‡è®°çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
2. å†…å®¹çš„å®Œæ•´æ€§å’Œåˆç†æ€§
3. æ ¼å¼çš„è§„èŒƒæ€§

æ–‡æ¡£å†…å®¹ï¼š
{{document}}

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºè¯„å®¡æŠ¥å‘Šï¼š
{{
  "summary": "æ€»ç»“",
  "issues": [
    {{
      "severity": "ä¸¥é‡/è­¦å‘Š/å»ºè®®",
      "location": "ä½ç½®",
      "description": "é—®é¢˜æè¿°",
      "suggestion": "ä¿®æ”¹å»ºè®®"
    }}
  ],
  "traceability_check": {{
    "all_have_id": true/false,
    "references_valid": true/false
  }}
}}
"""

    def _parse_markdown_review(self, content: str) -> dict:
        """è§£æ Markdown æ ¼å¼çš„è¯„å®¡æŠ¥å‘Š"""
        # ç®€åŒ–å®ç°ï¼šæå–å…³é”®ä¿¡æ¯
        return {
            "summary": "è¯„å®¡å®Œæˆ",
            "issues": [],
            "raw_content": content
        }
```

---

## **å››ã€CLI å‘½ä»¤å®ç°**

### **4.1 æ ¸å¿ƒå‘½ä»¤æµç¨‹**

**[ID: DD-CLI-001] [Designs-for: PRD-CMD-001]**

#### **å‘½ä»¤ï¼šspecgov init**

```python
# src/cli/commands/init.py

import click
from pathlib import Path
import shutil
import yaml

@click.command()
@click.argument('project_name')
@click.option('--ai', default='claude-code', help='AI åç«¯')
@click.option('--no-git', is_flag=True, help='ä¸åˆå§‹åŒ– Git')
def init(project_name: str, ai: str, no_git: bool):
    """åˆå§‹åŒ– SpecGovernor é¡¹ç›®"""

    click.echo(f"âœ“ åˆå§‹åŒ–é¡¹ç›®: {project_name}")
    click.echo(f"âœ“ AI åç«¯: {ai}")

    # 1. åˆ›å»ºç›®å½•ç»“æ„
    base_dir = Path('.specgov')
    base_dir.mkdir(exist_ok=True)

    (base_dir / 'artifacts').mkdir(exist_ok=True)
    (base_dir / 'reviews').mkdir(exist_ok=True)
    (base_dir / 'reports').mkdir(exist_ok=True)
    (base_dir / 'index').mkdir(exist_ok=True)
    (base_dir / 'context').mkdir(exist_ok=True)
    (base_dir / 'tasks').mkdir(exist_ok=True)

    click.echo("âœ“ ç›®å½•ç»“æ„ï¼š")
    click.echo("  .specgov/")
    click.echo("    â”œâ”€â”€ config.yml")
    click.echo("    â”œâ”€â”€ state.json")
    click.echo("    â”œâ”€â”€ index/")
    click.echo("    â”œâ”€â”€ artifacts/")
    click.echo("    â”œâ”€â”€ context/")
    click.echo("    â””â”€â”€ tasks/")

    # 2. ç”Ÿæˆé…ç½®æ–‡ä»¶
    config = {
        'project_name': project_name,
        'ai_backend': {
            'default': ai,
            'claude-code': {
                'command': 'claude-code execute',
                'model': 'claude-sonnet-4',
                'max_tokens': 200000
            }
        },
        'task_management': {
            'complexity_thresholds': {
                'simple': 5000,
                'medium': 10000,
                'complex': 20000
            }
        }
    }

    config_file = base_dir / 'config.yml'
    with open(config_file, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)

    # 3. ç”Ÿæˆ state.json
    state = {
        'current_role': None,
        'last_update': None
    }

    import json
    state_file = base_dir / 'state.json'
    with open(state_file, 'w') as f:
        json.dump(state, f, indent=2)

    # 4. åˆå§‹åŒ– Gitï¼ˆå¦‚æœéœ€è¦ï¼‰
    if not no_git:
        import subprocess
        try:
            subprocess.run(['git', 'init'], check=True, capture_output=True)
            click.echo("âœ“ Git ä»“åº“åˆå§‹åŒ–å®Œæˆ")
        except subprocess.CalledProcessError:
            click.echo("âš ï¸  Git åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰")

    # 5. è¾“å‡ºä¸‹ä¸€æ­¥æŒ‡å¼•
    click.echo("\nğŸ“š ä¸‹ä¸€æ­¥ï¼š")
    click.echo("  1. ç¼–è¾‘ .specgov/context/project-brief.md æ·»åŠ é¡¹ç›®èƒŒæ™¯")
    click.echo("  2. è¿è¡Œ specgov rd:generate å¼€å§‹ç”Ÿæˆéœ€æ±‚æ–‡æ¡£")
```

#### **å‘½ä»¤ï¼šspecgov rd:generate**

```python
# src/cli/commands/rd.py

import click
from pathlib import Path
from ...ai.generator import GeneratorAgent
from ...ai.claude_code import ClaudeCodeBackend
from ...storage.file_ops import save_artifact

@click.group()
def rd():
    """RD é˜¶æ®µå‘½ä»¤"""
    pass

@rd.command()
@click.option('--input', type=click.Path(exists=True), help='è¾“å…¥æ–‡ä»¶')
@click.option('--ai', default='claude-code', help='AI åç«¯')
@click.option('--output', default='.specgov/artifacts/rd.md', help='è¾“å‡ºè·¯å¾„')
def generate(input: str, ai: str, output: str):
    """ç”Ÿæˆéœ€æ±‚æ–‡æ¡£ (RD)"""

    click.echo("ğŸ¤– RD Generator Agent æ­£åœ¨å·¥ä½œ...")

    # 1. è¯»å–è¾“å…¥
    input_content = ""
    if input:
        click.echo(f"  è¯»å–è¾“å…¥ï¼š{input}")
        input_content = Path(input).read_text(encoding='utf-8')

    # 2. åˆå§‹åŒ– AI åç«¯
    click.echo(f"  è°ƒç”¨ AIï¼š{ai} (claude-sonnet-4)")
    backend = ClaudeCodeBackend()

    # 3. åˆ›å»º Generator Agent
    generator = GeneratorAgent(backend, stage='rd')

    # 4. ç”Ÿæˆæ–‡æ¡£
    click.echo("  ç”Ÿæˆä¸­...")
    result = generator.generate({'input_content': input_content})

    # 5. ä¿å­˜æ–‡æ¡£
    output_path = Path(output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(result, encoding='utf-8')

    click.echo(f"âœ“ ç”Ÿæˆå®Œæˆï¼š{output}")

    # 6. ç»Ÿè®¡ä¿¡æ¯
    # TODO: è§£ææ ‡è®°ï¼Œè¾“å‡ºç»Ÿè®¡

    click.echo("\nğŸ“š ä¸‹ä¸€æ­¥ï¼š")
    click.echo("  è¿è¡Œ specgov rd:review è¿›è¡Œè¯„å®¡")

@rd.command()
@click.option('--ai', default='gemini-cli', help='AI åç«¯ï¼ˆå»ºè®®ä½¿ç”¨ä¸åŒåç«¯ï¼‰')
def review(ai: str):
    """è¯„å®¡éœ€æ±‚æ–‡æ¡£ (RD)"""

    click.echo("ğŸ” RD Reviewer Agent æ­£åœ¨è¯„å®¡...")

    # 1. è¯»å–æ–‡æ¡£
    rd_file = Path('.specgov/artifacts/rd.md')
    if not rd_file.exists():
        click.echo("âœ— é”™è¯¯ï¼šRD æ–‡æ¡£ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ specgov rd:generate")
        return

    click.echo(f"  è¯»å–æ–‡æ¡£ï¼š{rd_file}")
    document = rd_file.read_text(encoding='utf-8')

    # 2. åˆå§‹åŒ– AI åç«¯
    click.echo(f"  è°ƒç”¨ AIï¼š{ai}")
    # TODO: æ”¯æŒå¤šåç«¯
    from ...ai.claude_code import ClaudeCodeBackend
    backend = ClaudeCodeBackend()

    # 3. åˆ›å»º Reviewer Agent
    from ...ai.reviewer import ReviewerAgent
    reviewer = ReviewerAgent(backend, stage='rd')

    # 4. è¯„å®¡
    click.echo("  è¯„å®¡ä¸­...")
    report = reviewer.review(document)

    # 5. ä¿å­˜è¯„å®¡æŠ¥å‘Š
    import json
    review_file = Path('.specgov/reviews/rd-review.json')
    review_file.parent.mkdir(parents=True, exist_ok=True)
    review_file.write_text(json.dumps(report, indent=2, ensure_ascii=False), encoding='utf-8')

    click.echo(f"âœ“ è¯„å®¡å®Œæˆï¼š{review_file}")

    # 6. è¾“å‡ºæ‘˜è¦
    click.echo("\nğŸ“‹ è¯„å®¡æŠ¥å‘Šï¼š")
    click.echo(f"æ€»ç»“ï¼š{report.get('summary', '')}")

    issues = report.get('issues', [])
    if issues:
        click.echo(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜ï¼š")
        for i, issue in enumerate(issues, 1):
            click.echo(f"  {i}. [{issue['severity']}] {issue['description']}")
    else:
        click.echo("âœ“ æœªå‘ç°é—®é¢˜")

    click.echo("\nğŸ“š ä¸‹ä¸€æ­¥ï¼š")
    click.echo("  è¿è¡Œ specgov rd:revise æ ¹æ®è¯„å®¡æ„è§ä¿®è®¢")
```

---

## **äº”ã€æ•°æ®å­˜å‚¨è®¾è®¡**

### **5.1 æ–‡ä»¶æ ¼å¼**

**[ID: DD-STORAGE-001]**

#### **ä¾èµ–å›¾å­˜å‚¨æ ¼å¼**

```json
// .specgov/index/dependency-graph.json
{
  "version": "1.0",
  "build_time": "2025-11-16T15:30:00Z",
  "nodes": [
    {
      "id": "RD-REQ-005",
      "type": "requirement",
      "file_path": "docs/rd.md",
      "line_number": 42,
      "context": "## 1.1 OAuth2 ç™»å½•",
      "metadata": {}
    }
  ],
  "edges": [
    {
      "source": "PRD-FEAT-012",
      "target": "RD-REQ-005",
      "type": "implements",
      "file_path": "docs/prd.md",
      "line_number": 128
    }
  ]
}
```

#### **ä»»åŠ¡æ–‡ä»¶æ ¼å¼**

```markdown
// .specgov/tasks/project.md
# SpecGovernor é¡¹ç›®ä»»åŠ¡ï¼ˆé¡¹ç›®ç»ç†è§†å›¾ï¼‰

> **é¡¹ç›®**: OAuth2 ç™»å½•åŠŸèƒ½
> **å¼€å§‹æ—¶é—´**: 2025-11-16 10:00

## Epic æ¦‚è§ˆ

| Epic | çŠ¶æ€ | è¿›åº¦ | è´Ÿè´£è§’è‰² | é¢„è®¡æ—¶é—´ | å®é™…æ—¶é—´ |
|------|------|------|---------|---------|---------|
| Epic 1: RD é˜¶æ®µ | âœ… å®Œæˆ | 3/3 (100%) | éœ€æ±‚åˆ†æå¸ˆ | 30åˆ†é’Ÿ | 35åˆ†é’Ÿ |
| Epic 2: PRD é˜¶æ®µ | â³ è¿›è¡Œä¸­ | 1/3 (33%) | äº§å“ç»ç† | 40åˆ†é’Ÿ | 15åˆ†é’Ÿ |

**æ€»è¿›åº¦**: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 27% (4/15)
```

---

## **å…­ã€æ€§èƒ½ä¼˜åŒ–è®¾è®¡**

### **6.1 ç´¢å¼•æ„å»ºä¼˜åŒ–**

**[ID: DD-PERF-001] [Designs-for: PRD-AC-002]**

**ç›®æ ‡ï¼š100ä¸‡è¡Œä»£ç  < 1åˆ†é’Ÿ**

ç­–ç•¥ï¼š
1. **å¹¶è¡Œè§£æ**ï¼šä½¿ç”¨å¤šè¿›ç¨‹è§£æå¤šä¸ªæ–‡ä»¶
2. **å¢é‡æ›´æ–°**ï¼šåŸºäº Git diff åªé‡æ–°è§£æå˜æ›´æ–‡ä»¶
3. **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜å·²è§£æçš„æ–‡ä»¶ï¼ˆåŸºäºæ–‡ä»¶å“ˆå¸Œï¼‰

```python
# ä¼ªä»£ç 
def build_index_parallel(files: List[Path], num_workers: int = 4):
    from multiprocessing import Pool

    with Pool(num_workers) as pool:
        results = pool.map(parse_file, files)

    return merge_results(results)
```

### **6.2 å½±å“åˆ†æä¼˜åŒ–**

**[ID: DD-PERF-002] [Designs-for: PRD-US-004.1]**

**ç›®æ ‡ï¼š< 10ç§’ï¼Œ$0æˆæœ¬**

ç­–ç•¥ï¼š
1. **çº¯å›¾æŸ¥è¯¢**ï¼šæ—  AI è°ƒç”¨ï¼ŒåªæŸ¥è¯¢å†…å­˜ä¸­çš„ä¾èµ–å›¾
2. **BFS ç®—æ³•**ï¼šå¹¿åº¦ä¼˜å…ˆæœç´¢ä¸‹æ¸¸èŠ‚ç‚¹
3. **ç´¢å¼•ä¼˜åŒ–**ï¼šä½¿ç”¨å“ˆå¸Œè¡¨åŠ é€ŸæŸ¥æ‰¾

---

## **ä¸ƒã€æµ‹è¯•ç­–ç•¥**

### **7.1 å•å…ƒæµ‹è¯•**

**[ID: DD-TEST-001]**

è¦†ç›–æ¨¡å—ï¼š
- Tag Parserï¼ˆæ ‡è®°è§£æå‡†ç¡®æ€§ > 95%ï¼‰
- Dependency Graphï¼ˆå›¾æ“ä½œæ­£ç¡®æ€§ï¼‰
- Impact Analyzerï¼ˆå½±å“åˆ†æå‡†ç¡®æ€§ï¼‰
- Task Complexity Checkerï¼ˆå¤æ‚åº¦åˆ¤æ–­å‡†ç¡®æ€§ï¼‰

### **7.2 é›†æˆæµ‹è¯•**

**[ID: DD-TEST-002]**

æµ‹è¯•åœºæ™¯ï¼š
- å®Œæ•´ RD â†’ PRD â†’ DD â†’ TD â†’ Code æµç¨‹
- å½±å“åˆ†æç«¯åˆ°ç«¯æµ‹è¯•
- ä¸€è‡´æ€§æ£€æŸ¥ç«¯åˆ°ç«¯æµ‹è¯•

### **7.3 æ€§èƒ½æµ‹è¯•**

**[ID: DD-TEST-003]**

æ€§èƒ½åŸºå‡†ï¼š
- ç´¢å¼•æ„å»ºï¼š100ä¸‡è¡Œä»£ç  < 1åˆ†é’Ÿ
- å½±å“åˆ†æï¼šä»»æ„é¡¹ç›® < 10ç§’
- ä¸€è‡´æ€§æ£€æŸ¥ï¼šå•éœ€æ±‚ < 2åˆ†é’Ÿ

---

## **å…«ã€å®ç°è®¡åˆ’**

### **8.1 MVPï¼ˆ10-14å‘¨ï¼‰**

**[ID: DD-IMPL-MVP]**

| å‘¨æ¬¡ | æ¨¡å— | å·¥ä½œå†…å®¹ |
|-----|------|---------|
| 1-2 | åŸºç¡€æ¡†æ¶ | Fork spec-kitï¼Œæ­å»ºé¡¹ç›®ç»“æ„ |
| 3-4 | Tag Parser | å®ç°æ ‡è®°è§£æå™¨ + å•å…ƒæµ‹è¯• |
| 5-6 | Dependency Graph | å®ç°ä¾èµ–å›¾ + å›¾ç®—æ³• |
| 7-8 | RD é˜¶æ®µ | å®ç° rd:generate/review/revise |
| 9-10 | Impact Analysis | å®ç°å½±å“åˆ†æå¼•æ“ |
| 11-12 | Consistency Check | å®ç°ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆå•éœ€æ±‚ï¼‰ |
| 13-14 | é›†æˆæµ‹è¯• | ç«¯åˆ°ç«¯æµ‹è¯• + Bugä¿®å¤ |

### **8.2 V1.0ï¼ˆMVP + 6-8å‘¨ï¼‰**

**[ID: DD-IMPL-V1]**

| å‘¨æ¬¡ | æ¨¡å— | å·¥ä½œå†…å®¹ |
|-----|------|---------|
| 15-16 | PRD/DD/TD é˜¶æ®µ | å®ç°å…¶ä»–æ–‡æ¡£é˜¶æ®µ |
| 17-18 | ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ | å®ç°ä¸¤å±‚ä»»åŠ¡ç®¡ç† |
| 19-20 | å¢é‡ç´¢å¼• | å®ç°å¢é‡æ›´æ–° |
| 21-22 | æ€§èƒ½ä¼˜åŒ– | å¹¶è¡ŒåŒ–ã€ç¼“å­˜ |

---

## **ä¹ã€é£é™©ç¼“è§£**

### **9.1 æŠ€æœ¯é£é™©**

**[ID: DD-RISK-001]**

| é£é™© | ç¼“è§£æªæ–½ |
|------|---------|
| AI ç”Ÿæˆæ ‡è®°ä¸å‡†ç¡® | Reviewer Agent æ£€æŸ¥ + æ‰‹åŠ¨ä¿®å¤å·¥å…· |
| ä¾èµ–å›¾æ„å»ºæ€§èƒ½ä¸è¶³ | å¹¶è¡Œè§£æ + å¢é‡æ›´æ–° |
| ä¸Šä¸‹æ–‡çª—å£è¶…é™ | ä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥ + è‡ªåŠ¨åˆ†è§£ |

---

## **åã€æ€»ç»“**

### **10.1 è®¾è®¡äº®ç‚¹**

**[ID: DD-SUMMARY-001]**

1. âœ… **å¤ç”¨ spec-kit**ï¼š60-70% ä»£ç å¤ç”¨ï¼ŒèŠ‚çœ 5-6 å‘¨å¼€å‘æ—¶é—´
2. âœ… **æ˜¾å¼è¿½æº¯**ï¼šåŸºäºæ­£åˆ™è¡¨è¾¾å¼è§£æï¼Œæ€§èƒ½é«˜ã€æˆæœ¬ä½
3. âœ… **ä¸¤å±‚ä»»åŠ¡ç®¡ç†**ï¼šé¡¹ç›®ç»ç†ç®¡ç† Epicï¼Œè§’è‰²ç®¡ç†ä»»åŠ¡
4. âœ… **æ— çŠ¶æ€è®¾è®¡**ï¼šæ‰€æœ‰çŠ¶æ€å­˜å‚¨åœ¨ Gitï¼Œæ”¯æŒè·¨ç”µè„‘å·¥ä½œ
5. âœ… **AI ä¸Šä¸‹æ–‡æ§åˆ¶**ï¼šä»»åŠ¡å¤æ‚åº¦æ£€æŸ¥ï¼Œé¿å…è¶…å‡ºçª—å£

### **10.2 ä¸‹ä¸€æ­¥**

**[ID: DD-NEXT-001]**

1. âœ… **ç¼–å†™ TDï¼ˆæµ‹è¯•æ–‡æ¡£ï¼‰**ï¼šè¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹å’Œç­–ç•¥
2. âœ… **å¼€å§‹å®ç°**ï¼šFork spec-kitï¼Œå¼€å§‹ç¼–ç 

---

**è®¾è®¡æ–‡æ¡£ç»“æŸ**
