# **ğŸ§ª æµ‹è¯•æ–‡æ¡£ (TD) - SpecGovernor**

> **Version**: v1.0
> **åŸºäº**: DD.md (v1.0) + RD.md (v1.0)
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-16
> **æµ‹è¯•ç›®æ ‡**: ç¡®ä¿ SpecGovernor ç³»ç»Ÿæ»¡è¶³æ‰€æœ‰åŠŸèƒ½ã€æ€§èƒ½å’Œæˆæœ¬è¦æ±‚

---

## **å¯è¿½æº¯æ€§å£°æ˜**

æœ¬æµ‹è¯•æ–‡æ¡£è®¾è®¡ä»¥ä¸‹éœ€æ±‚å’Œè®¾è®¡çš„æµ‹è¯•ï¼š
- [Tests-for: DD-ARCH-001] ç³»ç»Ÿæ•´ä½“æ¶æ„
- [Tests-for: DD-MOD-CLI-001] CLI Commands Layer
- [Tests-for: DD-MOD-CONTEXT-001] Context Builder
- [Tests-for: DD-MOD-STATE-001] State Manager
- [Tests-for: DD-MOD-PARSER-001] Tag Parser
- [Tests-for: DD-MOD-GRAPH-001] Dependency Graph
- [Tests-for: DD-MOD-ANALYZER-001] Impact Analyzer
- [Tests-for: DD-MOD-TASK-001] Task Management
- [Tests-for: RD-FR-1.1] Generator-Reviewer å¯¹æ¨¡å¼
- [Tests-for: RD-NFR-2.1] æ€§èƒ½éœ€æ±‚
- [Tests-for: RD-NFR-6.1] æˆæœ¬æ§åˆ¶

---

## **ä¸€ã€æµ‹è¯•ç­–ç•¥ (Test Strategy)**

### **1.1 æµ‹è¯•å±‚æ¬¡**

**[ID: TD-STRATEGY-001]**

| æµ‹è¯•å±‚æ¬¡ | æµ‹è¯•ç›®æ ‡ | è¦†ç›–èŒƒå›´ | å·¥å…· |
|---------|---------|---------|------|
| **å•å…ƒæµ‹è¯•** | éªŒè¯å„æ¨¡å—ç‹¬ç«‹åŠŸèƒ½çš„æ­£ç¡®æ€§ | æ‰€æœ‰æ ¸å¿ƒæ¨¡å—ï¼ˆTag Parser, Graph, Context Builder ç­‰ï¼‰ | pytest |
| **é›†æˆæµ‹è¯•** | éªŒè¯æ¨¡å—é—´åä½œçš„æ­£ç¡®æ€§ | CLI å‘½ä»¤ç«¯åˆ°ç«¯æµç¨‹ | pytest + fixtures |
| **æ€§èƒ½æµ‹è¯•** | éªŒè¯ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ | ç´¢å¼•æ„å»ºã€å½±å“åˆ†æã€ä¸€è‡´æ€§æ£€æŸ¥ | pytest-benchmark |
| **æˆæœ¬æµ‹è¯•** | éªŒè¯ AI è°ƒç”¨æˆæœ¬æ§åˆ¶ | æ‰€æœ‰æ¶‰åŠ AI çš„æ“ä½œ | è‡ªå®šä¹‰æˆæœ¬ç›‘æ§ |
| **ç«¯åˆ°ç«¯æµ‹è¯•** | éªŒè¯å®Œæ•´ SDLC æµç¨‹ | RD â†’ PRD â†’ DD â†’ TD â†’ Code | é›†æˆæµ‹è¯•æ¡†æ¶ |

### **1.2 æµ‹è¯•æ•°æ®å‡†å¤‡**

**[ID: TD-STRATEGY-002] [Tests-for: DD-TEST-001]**

**æµ‹è¯•é¡¹ç›®è§„æ¨¡åˆ†çº§**ï¼š

```yaml
å°å‹é¡¹ç›®:
  ä»£ç è¡Œæ•°: 1,000
  æ¨¡å—æ•°: 2
  éœ€æ±‚æ•°: 5
  ç”¨é€”: å¿«é€ŸåŠŸèƒ½æµ‹è¯•

ä¸­å‹é¡¹ç›®:
  ä»£ç è¡Œæ•°: 10,000
  æ¨¡å—æ•°: 5
  éœ€æ±‚æ•°: 20
  ç”¨é€”: é›†æˆæµ‹è¯•

å¤§å‹é¡¹ç›®:
  ä»£ç è¡Œæ•°: 100,000
  æ¨¡å—æ•°: 10
  éœ€æ±‚æ•°: 50
  ç”¨é€”: æ€§èƒ½æµ‹è¯•

è¶…å¤§é¡¹ç›®:
  ä»£ç è¡Œæ•°: 1,000,000
  æ¨¡å—æ•°: 20
  éœ€æ±‚æ•°: 100
  ç”¨é€”: å‹åŠ›æµ‹è¯•
```

### **1.3 æµ‹è¯•ç¯å¢ƒ**

**[ID: TD-STRATEGY-003]**

| ç¯å¢ƒç»„ä»¶ | ç‰ˆæœ¬/é…ç½® | è¯´æ˜ |
|---------|----------|------|
| **Python** | 3.11+ | æ ¸å¿ƒè¿è¡Œç¯å¢ƒ |
| **Click** | 8.x | CLI æ¡†æ¶ |
| **Claude Code** | latest | AI åç«¯ï¼ˆæ¨¡æ‹Ÿï¼‰ |
| **Git** | 2.x | ç‰ˆæœ¬æ§åˆ¶ |
| **pytest** | 8.x | æµ‹è¯•æ¡†æ¶ |
| **pytest-benchmark** | 4.x | æ€§èƒ½æµ‹è¯• |
| **pytest-mock** | 3.x | Mock å·¥å…· |

### **1.4 æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡**

**[ID: TD-STRATEGY-004]**

| æ¨¡å— | ä»£ç è¦†ç›–ç‡ç›®æ ‡ | åˆ†æ”¯è¦†ç›–ç‡ç›®æ ‡ |
|------|--------------|---------------|
| **Tag Parser** | â‰¥ 95% | â‰¥ 90% |
| **Dependency Graph** | â‰¥ 95% | â‰¥ 90% |
| **Context Builder** | â‰¥ 90% | â‰¥ 85% |
| **State Manager** | â‰¥ 95% | â‰¥ 90% |
| **Impact Analyzer** | â‰¥ 90% | â‰¥ 85% |
| **CLI Commands** | â‰¥ 85% | â‰¥ 80% |
| **Task Management** | â‰¥ 90% | â‰¥ 85% |
| **æ•´ä½“** | â‰¥ 90% | â‰¥ 85% |

---

## **äºŒã€å•å…ƒæµ‹è¯• (Unit Tests)**

### **2.1 Tag Parser æµ‹è¯•**

**[ID: TD-UNIT-PARSER-001] [Tests-for: DD-MOD-PARSER-001]**

#### **2.1.1 æ ‡è®°è§£æå‡†ç¡®æ€§æµ‹è¯•**

```python
# tests/unit/test_tag_parser.py

import pytest
from src.core.parser.tag_parser import TagParser
from src.core.parser.tag_types import TagType

class TestTagParser:
    """Tag Parser å•å…ƒæµ‹è¯•"""

    def test_parse_id_tag(self):
        """æµ‹è¯•è§£æ [ID: XXX] æ ‡è®°"""
        parser = TagParser()
        content = """
        # OAuth2 ç™»å½•éœ€æ±‚
        **[ID: RD-REQ-005]**
        ç³»ç»Ÿéœ€æ”¯æŒ OAuth2 ç™»å½•æµç¨‹ã€‚
        """

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)

            # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ°ä¸€ä¸ª ID æ ‡è®°
            assert len(result.tags) == 1
            assert result.tags[0].tag_type == TagType.ID
            assert result.tags[0].target_id == "RD-REQ-005"
            assert result.tags[0].line_number == 2
        finally:
            os.unlink(temp_file)

    def test_parse_implements_tag(self):
        """æµ‹è¯•è§£æ [Implements: XXX] æ ‡è®°"""
        parser = TagParser()
        content = """
        ## OAuth2 ç™»å½•åŠŸèƒ½
        **[ID: PRD-FEAT-012]** [Implements: RD-REQ-005]
        """

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)

            # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ° ID å’Œ Implements ä¸¤ä¸ªæ ‡è®°
            assert len(result.tags) == 2

            id_tag = [t for t in result.tags if t.tag_type == TagType.ID][0]
            assert id_tag.target_id == "PRD-FEAT-012"

            impl_tag = [t for t in result.tags if t.tag_type == TagType.IMPLEMENTS][0]
            assert impl_tag.target_id == "RD-REQ-005"
        finally:
            os.unlink(temp_file)

    def test_parse_multiple_tags_in_line(self):
        """æµ‹è¯•è§£æä¸€è¡Œä¸­çš„å¤šä¸ªæ ‡è®°"""
        parser = TagParser()
        content = "[ID: DD-API-008] [Designs-for: PRD-FEAT-012] [Implements: RD-REQ-005]"

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)

            # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ° 3 ä¸ªæ ‡è®°
            assert len(result.tags) == 3
            assert {t.tag_type for t in result.tags} == {
                TagType.ID,
                TagType.DESIGNS_FOR,
                TagType.IMPLEMENTS
            }
        finally:
            os.unlink(temp_file)

    def test_parse_code_file(self):
        """æµ‹è¯•è§£æä»£ç æ–‡ä»¶ä¸­çš„æ ‡è®°"""
        parser = TagParser()
        content = """
        // [ID: CODE-API-008] [Implements: DD-API-008]
        export class AuthController {
            async oauth2Callback(req: Request, res: Response) {
                // å®ç° OAuth2 å›è°ƒ
            }
        }
        """

        with tempfile.NamedTemporaryFile(mode='w', suffix='.ts', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)

            # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ° 2 ä¸ªæ ‡è®°
            assert len(result.tags) == 2
        finally:
            os.unlink(temp_file)

    def test_parse_invalid_tag_format(self):
        """æµ‹è¯•è§£ææ— æ•ˆæ ‡è®°æ ¼å¼"""
        parser = TagParser()
        content = "[InvalidTag: XXX] [ID: INVALID_FORMAT]"

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)

            # éªŒè¯ï¼šåº”è¯¥æœ‰é”™è¯¯è®°å½•
            assert len(result.errors) > 0
        finally:
            os.unlink(temp_file)

    @pytest.mark.benchmark
    def test_parse_large_file_performance(self, benchmark):
        """æµ‹è¯•å¤§æ–‡ä»¶è§£ææ€§èƒ½"""
        parser = TagParser()

        # ç”Ÿæˆ 10,000 è¡Œçš„æµ‹è¯•æ–‡ä»¶
        content = "\n".join([
            f"## Section {i}\n[ID: RD-REQ-{i:03d}]"
            for i in range(1, 10001)
        ])

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            # æ€§èƒ½åŸºå‡†æµ‹è¯•
            result = benchmark(parser.parse_file, temp_file)

            # éªŒè¯ï¼šè§£ææ—¶é—´åº”è¯¥ < 1 ç§’
            assert benchmark.stats['mean'] < 1.0

            # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ° 10,000 ä¸ªæ ‡è®°
            assert len(result.tags) == 10000
        finally:
            os.unlink(temp_file)
```

#### **2.1.2 è¾¹ç•Œæƒ…å†µæµ‹è¯•**

```python
class TestTagParserEdgeCases:
    """Tag Parser è¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    def test_parse_empty_file(self):
        """æµ‹è¯•è§£æç©ºæ–‡ä»¶"""
        parser = TagParser()

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write("")
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)
            assert len(result.tags) == 0
            assert len(result.errors) == 0
        finally:
            os.unlink(temp_file)

    def test_parse_file_not_found(self):
        """æµ‹è¯•è§£æä¸å­˜åœ¨çš„æ–‡ä»¶"""
        parser = TagParser()
        result = parser.parse_file("non_existent_file.md")

        assert len(result.errors) > 0
        assert "not found" in result.errors[0].lower()

    def test_parse_unsupported_file_type(self):
        """æµ‹è¯•è§£æä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"""
        parser = TagParser()

        with tempfile.NamedTemporaryFile(mode='w', suffix='.pdf', delete=False) as f:
            f.write("Some content")
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)
            assert len(result.warnings) > 0
        finally:
            os.unlink(temp_file)

    def test_parse_with_special_characters(self):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ ‡è®°"""
        parser = TagParser()
        content = "[ID: RD-REQ-001] åŒ…å«ä¸­æ–‡ã€emoji ğŸ˜Š å’Œç‰¹æ®Šç¬¦å· @#$%"

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(content)
            temp_file = f.name

        try:
            result = parser.parse_file(temp_file)
            assert len(result.tags) == 1
            assert result.tags[0].target_id == "RD-REQ-001"
        finally:
            os.unlink(temp_file)
```

---

### **2.2 Dependency Graph æµ‹è¯•**

**[ID: TD-UNIT-GRAPH-001] [Tests-for: DD-MOD-GRAPH-001]**

#### **2.2.1 å›¾æ“ä½œæ­£ç¡®æ€§æµ‹è¯•**

```python
# tests/unit/test_dependency_graph.py

import pytest
from src.core.graph.graph import DependencyGraph
from src.core.graph.node import Node, NodeType
from src.core.graph.edge import Edge, EdgeType

class TestDependencyGraph:
    """Dependency Graph å•å…ƒæµ‹è¯•"""

    def test_add_node(self):
        """æµ‹è¯•æ·»åŠ èŠ‚ç‚¹"""
        graph = DependencyGraph()

        node = Node(
            id="RD-REQ-005",
            type=NodeType.REQUIREMENT,
            file_path="docs/RD.md",
            line_number=42
        )

        graph.add_node(node)

        assert "RD-REQ-005" in graph.nodes
        assert graph.nodes["RD-REQ-005"].type == NodeType.REQUIREMENT

    def test_add_edge(self):
        """æµ‹è¯•æ·»åŠ è¾¹"""
        graph = DependencyGraph()

        # æ·»åŠ èŠ‚ç‚¹
        node1 = Node("RD-REQ-005", NodeType.REQUIREMENT, "docs/RD.md", 42)
        node2 = Node("PRD-FEAT-012", NodeType.FEATURE, "docs/PRD.md", 128)
        graph.add_node(node1)
        graph.add_node(node2)

        # æ·»åŠ è¾¹
        edge = Edge(
            source_id="PRD-FEAT-012",
            target_id="RD-REQ-005",
            edge_type=EdgeType.IMPLEMENTS,
            file_path="docs/PRD.md",
            line_number=128
        )
        graph.add_edge(edge)

        # éªŒè¯
        assert len(graph.outgoing_edges["PRD-FEAT-012"]) == 1
        assert len(graph.incoming_edges["RD-REQ-005"]) == 1

    def test_get_downstream_nodes(self):
        """æµ‹è¯•è·å–ä¸‹æ¸¸èŠ‚ç‚¹"""
        graph = self._create_sample_graph()

        # RD-REQ-005 çš„ä¸‹æ¸¸åº”è¯¥åŒ…æ‹¬ PRD-FEAT-012 å’Œ DD-API-008
        downstream = graph.get_downstream_nodes("RD-REQ-005")

        downstream_ids = {node.id for node in downstream}
        assert "PRD-FEAT-012" in downstream_ids
        assert "DD-API-008" in downstream_ids

    def test_get_upstream_nodes(self):
        """æµ‹è¯•è·å–ä¸Šæ¸¸èŠ‚ç‚¹"""
        graph = self._create_sample_graph()

        # DD-API-008 çš„ä¸Šæ¸¸åº”è¯¥åŒ…æ‹¬ PRD-FEAT-012 å’Œ RD-REQ-005
        upstream = graph.get_upstream_nodes("DD-API-008")

        upstream_ids = {node.id for node in upstream}
        assert "PRD-FEAT-012" in upstream_ids
        assert "RD-REQ-005" in upstream_ids

    def test_detect_cycles(self):
        """æµ‹è¯•æ£€æµ‹å¾ªç¯ä¾èµ–"""
        graph = DependencyGraph()

        # åˆ›å»ºå¾ªç¯ä¾èµ–ï¼šA -> B -> C -> A
        nodes = [
            Node("A", NodeType.REQUIREMENT, "test.md", 1),
            Node("B", NodeType.FEATURE, "test.md", 2),
            Node("C", NodeType.API_DESIGN, "test.md", 3),
        ]
        for node in nodes:
            graph.add_node(node)

        edges = [
            Edge("A", "B", EdgeType.IMPLEMENTS, "test.md", 1),
            Edge("B", "C", EdgeType.DESIGNS_FOR, "test.md", 2),
            Edge("C", "A", EdgeType.IMPLEMENTS, "test.md", 3),  # å¾ªç¯
        ]
        for edge in edges:
            graph.add_edge(edge)

        # æ£€æµ‹å¾ªç¯
        cycles = graph.detect_cycles()

        assert len(cycles) > 0
        assert set(cycles[0]) == {"A", "B", "C"}

    def test_serialization(self):
        """æµ‹è¯•åºåˆ—åŒ–ä¸ååºåˆ—åŒ–"""
        graph = self._create_sample_graph()

        # åºåˆ—åŒ–
        json_data = graph.to_json()

        # éªŒè¯ JSON ç»“æ„
        assert "nodes" in json_data
        assert "edges" in json_data
        assert len(json_data["nodes"]) == 3
        assert len(json_data["edges"]) == 2

        # ååºåˆ—åŒ–
        graph2 = DependencyGraph.from_json(json_data)

        # éªŒè¯
        assert len(graph2.nodes) == 3
        assert "RD-REQ-005" in graph2.nodes

    def _create_sample_graph(self) -> DependencyGraph:
        """åˆ›å»ºç¤ºä¾‹ä¾èµ–å›¾"""
        graph = DependencyGraph()

        # æ·»åŠ èŠ‚ç‚¹
        nodes = [
            Node("RD-REQ-005", NodeType.REQUIREMENT, "docs/RD.md", 42),
            Node("PRD-FEAT-012", NodeType.FEATURE, "docs/PRD.md", 128),
            Node("DD-API-008", NodeType.API_DESIGN, "docs/DD.md", 234),
        ]
        for node in nodes:
            graph.add_node(node)

        # æ·»åŠ è¾¹
        edges = [
            Edge("PRD-FEAT-012", "RD-REQ-005", EdgeType.IMPLEMENTS, "docs/PRD.md", 128),
            Edge("DD-API-008", "PRD-FEAT-012", EdgeType.DESIGNS_FOR, "docs/DD.md", 234),
        ]
        for edge in edges:
            graph.add_edge(edge)

        return graph
```

---

### **2.3 Context Builder æµ‹è¯•**

**[ID: TD-UNIT-CONTEXT-001] [Tests-for: DD-MOD-CONTEXT-001]**

```python
# tests/unit/test_context_builder.py

import pytest
from src.context.builder import ContextBuilder

class TestContextBuilder:
    """Context Builder å•å…ƒæµ‹è¯•"""

    def test_build_for_rd_generation(self, tmp_path):
        """æµ‹è¯•ä¸º RD ç”Ÿæˆæ„å»ºä¸Šä¸‹æ–‡"""
        # åˆ›å»ºä¸´æ—¶é¡¹ç›®ç›®å½•
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        # åˆ›å»ºä¸Šä¸‹æ–‡æ–‡ä»¶
        context_dir = project_dir / ".specgov" / "context"
        context_dir.mkdir(parents=True)

        brief_file = context_dir / "project-brief.md"
        brief_file.write_text("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡¹ç›®")

        # åˆ›å»º Context Builder
        builder = ContextBuilder(project_dir)

        # æ„å»ºä¸Šä¸‹æ–‡
        prompt = builder.build_for_rd_generation("ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚")

        # éªŒè¯
        assert "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡¹ç›®" in prompt
        assert "ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚" in prompt

    def test_token_limit_enforcement(self, tmp_path):
        """æµ‹è¯• Token é™åˆ¶å¼ºåˆ¶æ‰§è¡Œ"""
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        builder = ContextBuilder(project_dir)

        # ç”Ÿæˆè¶…å¤§æ–‡æœ¬ï¼ˆçº¦ 30K tokensï¼‰
        large_text = "X" * (30000 * builder.CHARS_PER_TOKEN)

        # è£å‰ª
        trimmed = builder._ensure_token_limit(large_text, max_tokens=5000)

        # éªŒè¯ï¼šè£å‰ªååº”è¯¥ä¸è¶…è¿‡ 5K tokens
        estimated_tokens = len(trimmed) // builder.CHARS_PER_TOKEN
        assert estimated_tokens <= 5000

    def test_extract_relevant_sections(self):
        """æµ‹è¯•æå–ç›¸å…³ç« èŠ‚"""
        builder = ContextBuilder(".")

        content = """
        # ç¬¬ä¸€ç« 
        [ID: RD-REQ-001]
        å†…å®¹ 1

        # ç¬¬äºŒç« 
        [ID: RD-REQ-002]
        å†…å®¹ 2
        """ * 100  # é‡å¤ 100 æ¬¡

        # æå–ç›¸å…³ç« èŠ‚ï¼ˆé™åˆ¶ä¸º 2000 tokensï¼‰
        excerpt = builder._extract_relevant_sections(content, max_tokens=2000)

        # éªŒè¯ï¼šåº”è¯¥è¢«è£å‰ª
        assert len(excerpt) < len(content)
        assert "å†…å®¹å·²è£å‰ª" in excerpt
```

---

### **2.4 State Manager æµ‹è¯•**

**[ID: TD-UNIT-STATE-001] [Tests-for: DD-MOD-STATE-001]**

```python
# tests/unit/test_state_manager.py

import pytest
from src.state.manager import StateManager

class TestStateManager:
    """State Manager å•å…ƒæµ‹è¯•"""

    def test_get_default_state(self, tmp_path):
        """æµ‹è¯•è·å–é»˜è®¤çŠ¶æ€"""
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        manager = StateManager(project_dir)
        state = manager.get_state()

        # éªŒè¯é»˜è®¤çŠ¶æ€
        assert state['rd_generated'] == False
        assert state['prd_generated'] == False
        assert state['total_cost'] == 0.0

    def test_update_state(self, tmp_path):
        """æµ‹è¯•æ›´æ–°çŠ¶æ€"""
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        manager = StateManager(project_dir)

        # æ›´æ–°çŠ¶æ€
        manager.update({'rd_generated': True, 'rd_version': 1})

        # è¯»å–çŠ¶æ€
        state = manager.get_state()

        # éªŒè¯
        assert state['rd_generated'] == True
        assert state['rd_version'] == 1

    def test_can_generate_prd(self, tmp_path):
        """æµ‹è¯• PRD ç”Ÿæˆå‰ç½®æ¡ä»¶æ£€æŸ¥"""
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        manager = StateManager(project_dir)

        # åˆå§‹çŠ¶æ€ï¼šRD æœªç”Ÿæˆ
        assert manager.can_generate_prd() == False

        # æ›´æ–°çŠ¶æ€ï¼šRD å·²ç”Ÿæˆ
        manager.update({'rd_generated': True})

        # éªŒè¯ï¼šç°åœ¨å¯ä»¥ç”Ÿæˆ PRD
        assert manager.can_generate_prd() == True

    def test_record_generation(self, tmp_path):
        """æµ‹è¯•è®°å½•ç”Ÿæˆæ“ä½œ"""
        project_dir = tmp_path / "test_project"
        project_dir.mkdir()

        manager = StateManager(project_dir)

        # è®°å½•ç”Ÿæˆæ“ä½œ
        manager.record_generation(
            stage='rd',
            cost=0.05,
            tokens=1500,
            time_seconds=45.0
        )

        # è¯»å–çŠ¶æ€
        state = manager.get_state()

        # éªŒè¯
        assert state['rd_generated'] == True
        assert state['rd_version'] == 1
        assert state['total_cost'] == 0.05
        assert state['total_tokens'] == 1500
```

---

### **2.5 Task Complexity Checker æµ‹è¯•**

**[ID: TD-UNIT-TASK-001] [Tests-for: DD-MOD-TASK-001]**

```python
# tests/unit/test_complexity_checker.py

import pytest
from src.tasks.complexity import ComplexityChecker
from src.tasks.task import Task, TaskStatus, TaskComplexity

class TestComplexityChecker:
    """Task Complexity Checker å•å…ƒæµ‹è¯•"""

    def test_simple_task(self, tmp_path):
        """æµ‹è¯•ç®€å•ä»»åŠ¡æ£€æµ‹"""
        checker = ComplexityChecker()

        # åˆ›å»ºå°æ–‡ä»¶
        test_file = tmp_path / "test.md"
        test_file.write_text("X" * 1000)  # çº¦ 250 tokens

        task = Task(
            id="TASK-001",
            epic_id="EPIC-001",
            title="ç®€å•ä»»åŠ¡",
            status=TaskStatus.PENDING,
            command="test",
            context_files=[str(test_file)]
        )

        complexity, warning = checker.check_task(task)

        assert complexity == TaskComplexity.SIMPLE
        assert warning is None

    def test_complex_task(self, tmp_path):
        """æµ‹è¯•å¤æ‚ä»»åŠ¡æ£€æµ‹"""
        checker = ComplexityChecker()

        # åˆ›å»ºå¤§æ–‡ä»¶
        test_file = tmp_path / "test.md"
        test_file.write_text("X" * 50000)  # çº¦ 12K tokens

        task = Task(
            id="TASK-001",
            epic_id="EPIC-001",
            title="å¤æ‚ä»»åŠ¡",
            status=TaskStatus.PENDING,
            command="test",
            context_files=[str(test_file)]
        )

        complexity, warning = checker.check_task(task)

        assert complexity == TaskComplexity.COMPLEX
        assert warning is not None

    def test_too_complex_task(self, tmp_path):
        """æµ‹è¯•è¿‡äºå¤æ‚çš„ä»»åŠ¡æ£€æµ‹"""
        checker = ComplexityChecker()

        # åˆ›å»ºè¶…å¤§æ–‡ä»¶
        test_file = tmp_path / "test.md"
        test_file.write_text("X" * 100000)  # çº¦ 25K tokens

        task = Task(
            id="TASK-001",
            epic_id="EPIC-001",
            title="è¿‡äºå¤æ‚çš„ä»»åŠ¡",
            status=TaskStatus.PENDING,
            command="test",
            context_files=[str(test_file)]
        )

        complexity, warning = checker.check_task(task)

        assert complexity == TaskComplexity.TOO_COMPLEX
        assert "å»ºè®®åˆ†è§£" in warning
```

---

## **ä¸‰ã€é›†æˆæµ‹è¯• (Integration Tests)**

### **3.1 å®Œæ•´æ–‡æ¡£ç”Ÿæˆæµç¨‹æµ‹è¯•**

**[ID: TD-INTEGRATION-001] [Tests-for: RD-WORKFLOW-001]**

```python
# tests/integration/test_document_workflow.py

import pytest
from click.testing import CliRunner
from src.cli.main import cli

class TestDocumentWorkflow:
    """æ–‡æ¡£ç”Ÿæˆæµç¨‹é›†æˆæµ‹è¯•"""

    def test_rd_generation_flow(self, tmp_path, mocker):
        """æµ‹è¯•å®Œæ•´çš„ RD ç”Ÿæˆæµç¨‹"""
        runner = CliRunner()

        # 1. åˆå§‹åŒ–é¡¹ç›®
        with runner.isolated_filesystem(temp_dir=tmp_path):
            result = runner.invoke(cli, ['init', 'test-project'])
            assert result.exit_code == 0
            assert ".specgov" in os.listdir()

            # 2. åˆ›å»ºè¾“å…¥æ–‡ä»¶
            with open("user-stories.md", "w") as f:
                f.write("ç”¨æˆ·éœ€è¦ OAuth2 ç™»å½•åŠŸèƒ½")

            # 3. Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content="# RD\n[ID: RD-REQ-001] OAuth2 ç™»å½•",
                tokens_input=100,
                tokens_output=200,
                cost=0.05,
                model="claude-sonnet-4",
                backend="claude-code"
            )

            # 4. ç”Ÿæˆ RD
            result = runner.invoke(cli, ['rd:generate', '--input=user-stories.md'])
            assert result.exit_code == 0

            # 5. éªŒè¯è¾“å‡ºæ–‡ä»¶
            assert os.path.exists(".specgov/artifacts/rd.md")

            # 6. éªŒè¯çŠ¶æ€æ›´æ–°
            import json
            with open(".specgov/state.json") as f:
                state = json.load(f)
            assert state['rd_generated'] == True

    def test_rd_review_flow(self, tmp_path, mocker):
        """æµ‹è¯• RD è¯„å®¡æµç¨‹"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=tmp_path):
            # å‡†å¤‡ç¯å¢ƒ
            self._setup_project(runner)

            # åˆ›å»º RD æ–‡æ¡£
            os.makedirs(".specgov/artifacts", exist_ok=True)
            with open(".specgov/artifacts/rd.md", "w") as f:
                f.write("# RD\n[ID: RD-REQ-001] OAuth2 ç™»å½•")

            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"summary": "è¯„å®¡å®Œæˆ", "issues": []}',
                tokens_input=200,
                tokens_output=100,
                cost=0.03,
                model="claude-sonnet-4",
                backend="claude-code"
            )

            # æ‰§è¡Œè¯„å®¡
            result = runner.invoke(cli, ['rd:review'])
            assert result.exit_code == 0

            # éªŒè¯è¯„å®¡æŠ¥å‘Š
            assert os.path.exists(".specgov/reviews/rd-review.json")

    def _setup_project(self, runner):
        """è®¾ç½®æµ‹è¯•é¡¹ç›®"""
        result = runner.invoke(cli, ['init', 'test-project'])
        assert result.exit_code == 0
```

---

### **3.2 ç´¢å¼•æ„å»ºä¸ä¾èµ–å›¾æµ‹è¯•**

**[ID: TD-INTEGRATION-002] [Tests-for: RD-FR-2.1]**

```python
# tests/integration/test_index_building.py

import pytest
from click.testing import CliRunner
from src.cli.main import cli

class TestIndexBuilding:
    """ç´¢å¼•æ„å»ºé›†æˆæµ‹è¯•"""

    def test_build_index_from_scratch(self, sample_project):
        """æµ‹è¯•ä»é›¶æ„å»ºç´¢å¼•"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ‰§è¡Œç´¢å¼•æ„å»º
            result = runner.invoke(cli, ['index:build'])
            assert result.exit_code == 0

            # éªŒè¯ç´¢å¼•æ–‡ä»¶
            assert os.path.exists(".specgov/index/dependency-graph.json")
            assert os.path.exists(".specgov/index/modules.json")

            # éªŒè¯ä¾èµ–å›¾å†…å®¹
            import json
            with open(".specgov/index/dependency-graph.json") as f:
                graph = json.load(f)

            assert "nodes" in graph
            assert "edges" in graph
            assert len(graph["nodes"]) > 0

    def test_incremental_index_update(self, sample_project):
        """æµ‹è¯•å¢é‡ç´¢å¼•æ›´æ–°"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # 1. æ„å»ºåˆå§‹ç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # 2. ä¿®æ”¹æ–‡æ¡£
            with open("docs/RD.md", "a") as f:
                f.write("\n[ID: RD-REQ-999] æ–°å¢éœ€æ±‚")

            # 3. å¢é‡æ›´æ–°
            result = runner.invoke(cli, ['index:update', '--changed=docs/RD.md'])
            assert result.exit_code == 0

            # 4. éªŒè¯æ–°èŠ‚ç‚¹å·²æ·»åŠ 
            import json
            with open(".specgov/index/dependency-graph.json") as f:
                graph = json.load(f)

            node_ids = [node["id"] for node in graph["nodes"]]
            assert "RD-REQ-999" in node_ids
```

---

### **3.3 å½±å“åˆ†æç«¯åˆ°ç«¯æµ‹è¯•**

**[ID: TD-INTEGRATION-003] [Tests-for: RD-WORKFLOW-002]**

```python
# tests/integration/test_impact_analysis.py

import pytest
import time
from click.testing import CliRunner
from src.cli.main import cli

class TestImpactAnalysis:
    """å½±å“åˆ†æé›†æˆæµ‹è¯•"""

    def test_impact_analysis_performance(self, large_sample_project):
        """æµ‹è¯•å½±å“åˆ†ææ€§èƒ½ï¼ˆ< 10ç§’ï¼‰"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=large_sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # ä¿®æ”¹æ–‡ä»¶
            with open("docs/RD.md", "a") as f:
                f.write("\n[ID: RD-REQ-999] ä¿®æ”¹éœ€æ±‚")

            # æ‰§è¡Œå½±å“åˆ†æï¼ˆè®¡æ—¶ï¼‰
            start_time = time.time()
            result = runner.invoke(cli, ['analyze:impact', '--changed=docs/RD.md'])
            elapsed_time = time.time() - start_time

            # éªŒè¯
            assert result.exit_code == 0
            assert elapsed_time < 10.0  # æ€§èƒ½è¦æ±‚ï¼š< 10ç§’

            # éªŒè¯è¾“å‡º
            assert "affected" in result.output.lower()

    def test_impact_analysis_accuracy(self, sample_project):
        """æµ‹è¯•å½±å“åˆ†æå‡†ç¡®æ€§"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # ä¿®æ”¹ RD
            with open("docs/RD.md", "a") as f:
                f.write("\n[ID: RD-REQ-005] ä¿®æ”¹ OAuth2 éœ€æ±‚")

            # æ‰§è¡Œå½±å“åˆ†æ
            result = runner.invoke(cli, ['analyze:impact', '--changed=docs/RD.md', '--format=json'])
            assert result.exit_code == 0

            # è§£æè¾“å‡º
            import json
            report = json.loads(result.output)

            # éªŒè¯ï¼šåº”è¯¥åŒ…å«ä¸‹æ¸¸èŠ‚ç‚¹
            affected_ids = [item["id"] for item in report["affected_documents"]]
            assert "PRD-FEAT-012" in affected_ids  # PRD åº”è¯¥å—å½±å“
```

---

### **3.4 ä¸€è‡´æ€§æ£€æŸ¥ç«¯åˆ°ç«¯æµ‹è¯•**

**[ID: TD-INTEGRATION-004] [Tests-for: RD-WORKFLOW-003]**

```python
# tests/integration/test_consistency_check.py

import pytest
import time
from click.testing import CliRunner
from src.cli.main import cli

class TestConsistencyCheck:
    """ä¸€è‡´æ€§æ£€æŸ¥é›†æˆæµ‹è¯•"""

    def test_single_requirement_check(self, sample_project, mocker):
        """æµ‹è¯•å•ä¸ªéœ€æ±‚çš„ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆ< 2åˆ†é’Ÿï¼‰"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": []}',
                tokens_input=3000,
                tokens_output=500,
                cost=0.02,
                model="claude-sonnet-4"
            )

            # æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼ˆè®¡æ—¶ï¼‰
            start_time = time.time()
            result = runner.invoke(cli, ['check:consistency', '--scope=RD-REQ-005'])
            elapsed_time = time.time() - start_time

            # éªŒè¯
            assert result.exit_code == 0
            assert elapsed_time < 120.0  # æ€§èƒ½è¦æ±‚ï¼š< 2åˆ†é’Ÿ

    def test_module_level_check(self, sample_project, mocker):
        """æµ‹è¯•æ¨¡å—çº§ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆ< 2åˆ†é’Ÿï¼‰"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": [{"severity": "warning", "description": "API ä¸åŒ¹é…"}]}',
                tokens_input=15000,
                tokens_output=1000,
                cost=0.05,
                model="claude-sonnet-4"
            )

            # æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥
            start_time = time.time()
            result = runner.invoke(cli, ['check:consistency', '--scope=AuthModule'])
            elapsed_time = time.time() - start_time

            # éªŒè¯
            assert result.exit_code == 0
            assert elapsed_time < 120.0  # æ€§èƒ½è¦æ±‚ï¼š< 2åˆ†é’Ÿ
            assert "ä¸ä¸€è‡´" in result.output or "inconsistenc" in result.output.lower()

    def test_detect_inconsistency(self, inconsistent_project, mocker):
        """æµ‹è¯•æ£€æµ‹ä¸ä¸€è‡´æ€§"""
        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=inconsistent_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # Mock AI åç«¯è¿”å›ä¸ä¸€è‡´æŠ¥å‘Š
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='''{
                    "inconsistencies": [
                        {
                            "severity": "error",
                            "description": "DD è®¾è®¡çš„ API æ˜¯ POST /paymentsï¼Œä»£ç å®ç°æ˜¯ PUT /payments",
                            "rd_ref": "RD-REQ-010",
                            "prd_ref": "PRD-FEAT-020",
                            "dd_ref": "DD-API-015",
                            "code_ref": "CODE-API-015"
                        }
                    ]
                }''',
                tokens_input=5000,
                tokens_output=800,
                cost=0.03,
                model="claude-sonnet-4"
            )

            # æ‰§è¡Œæ£€æŸ¥
            result = runner.invoke(cli, ['check:consistency', '--scope=PaymentModule'])

            # éªŒè¯
            assert result.exit_code != 0  # å‘ç°ä¸ä¸€è‡´åº”è¯¥è¿”å›éé›¶é€€å‡ºç 
            assert "ä¸ä¸€è‡´" in result.output or "inconsistenc" in result.output.lower()
```

---

## **å››ã€æ€§èƒ½æµ‹è¯• (Performance Tests)**

### **4.1 ç´¢å¼•æ„å»ºæ€§èƒ½æµ‹è¯•**

**[ID: TD-PERF-INDEX-001] [Tests-for: RD-NFR-2.5]**

```python
# tests/performance/test_index_performance.py

import pytest
import time
from src.core.parser.tag_parser import TagParser
from src.core.graph.builder import GraphBuilder

class TestIndexPerformance:
    """ç´¢å¼•æ„å»ºæ€§èƒ½æµ‹è¯•"""

    @pytest.mark.benchmark
    def test_parse_1m_lines_project(self, million_line_project, benchmark):
        """æµ‹è¯•è§£æ 100 ä¸‡è¡Œä»£ç é¡¹ç›®ï¼ˆ< 1åˆ†é’Ÿï¼‰"""
        parser = TagParser()

        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        result = benchmark(parser.parse_directory, million_line_project)

        # éªŒè¯ï¼šè§£ææ—¶é—´åº”è¯¥ < 60 ç§’
        assert benchmark.stats['mean'] < 60.0

        # éªŒè¯ï¼šåº”è¯¥æ‰¾åˆ°å¤§é‡æ ‡è®°
        total_tags = sum(len(r.tags) for r in result)
        assert total_tags > 0

    @pytest.mark.benchmark
    def test_build_dependency_graph(self, million_line_project, benchmark):
        """æµ‹è¯•æ„å»ºä¾èµ–å›¾ï¼ˆ< 1åˆ†é’Ÿï¼‰"""
        builder = GraphBuilder()

        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        graph = benchmark(builder.build_from_directory, million_line_project)

        # éªŒè¯ï¼šæ„å»ºæ—¶é—´åº”è¯¥ < 60 ç§’
        assert benchmark.stats['mean'] < 60.0

        # éªŒè¯ï¼šå›¾åº”è¯¥åŒ…å«èŠ‚ç‚¹
        assert len(graph.nodes) > 0

    def test_incremental_update_performance(self, sample_project):
        """æµ‹è¯•å¢é‡æ›´æ–°æ€§èƒ½ï¼ˆ< 5ç§’ï¼‰"""
        builder = GraphBuilder()

        # 1. æ„å»ºåˆå§‹å›¾
        graph = builder.build_from_directory(sample_project)

        # 2. ä¿®æ”¹å•ä¸ªæ–‡ä»¶
        test_file = sample_project / "docs" / "RD.md"
        with open(test_file, "a") as f:
            f.write("\n[ID: RD-REQ-999] æ–°å¢éœ€æ±‚")

        # 3. å¢é‡æ›´æ–°ï¼ˆè®¡æ—¶ï¼‰
        start_time = time.time()

        # åªé‡æ–°è§£æå˜æ›´æ–‡ä»¶
        parser = TagParser()
        result = parser.parse_file(test_file)

        # æ›´æ–°å›¾
        for tag in result.tags:
            if tag.tag_type.value == "ID":
                from src.core.graph.node import Node, NodeType
                node = Node(tag.target_id, NodeType.REQUIREMENT, str(test_file), tag.line_number)
                graph.add_node(node)

        elapsed_time = time.time() - start_time

        # éªŒè¯ï¼šå¢é‡æ›´æ–°åº”è¯¥ < 5 ç§’
        assert elapsed_time < 5.0
```

---

### **4.2 å½±å“åˆ†ææ€§èƒ½æµ‹è¯•**

**[ID: TD-PERF-IMPACT-001] [Tests-for: RD-NFR-2.1]**

```python
# tests/performance/test_impact_performance.py

import pytest
import time
from src.core.analyzer.impact import ImpactAnalyzer

class TestImpactPerformance:
    """å½±å“åˆ†ææ€§èƒ½æµ‹è¯•"""

    def test_impact_analysis_response_time(self, large_dependency_graph):
        """æµ‹è¯•å½±å“åˆ†æå“åº”æ—¶é—´ï¼ˆ< 10ç§’ï¼‰"""
        from pathlib import Path
        analyzer = ImpactAnalyzer(large_dependency_graph, Path("."))

        # æ¨¡æ‹Ÿå˜æ›´æ–‡ä»¶
        changed_file = Path("docs/RD.md")

        # æ‰§è¡Œå½±å“åˆ†æï¼ˆè®¡æ—¶ï¼‰
        start_time = time.time()
        report = analyzer.analyze_file_change(changed_file)
        elapsed_time = time.time() - start_time

        # éªŒè¯ï¼šå“åº”æ—¶é—´åº”è¯¥ < 10 ç§’
        assert elapsed_time < 10.0

        # éªŒè¯ï¼šåº”è¯¥è¿”å›å½±å“æŠ¥å‘Š
        assert "changed_file" in report
        assert "affected_documents" in report

    @pytest.mark.parametrize("project_size", [10, 50, 100])
    def test_impact_scalability(self, project_size):
        """æµ‹è¯•å½±å“åˆ†æå¯æ‰©å±•æ€§"""
        # åˆ›å»ºä¸åŒè§„æ¨¡çš„ä¾èµ–å›¾
        graph = self._create_graph_with_size(project_size)

        from pathlib import Path
        analyzer = ImpactAnalyzer(graph, Path("."))

        # æ‰§è¡Œå½±å“åˆ†æ
        start_time = time.time()
        report = analyzer.analyze_file_change(Path("test.md"))
        elapsed_time = time.time() - start_time

        # éªŒè¯ï¼šå³ä½¿é¡¹ç›®è§„æ¨¡å¢å¤§ï¼Œå“åº”æ—¶é—´ä¹Ÿåº”è¯¥ < 10 ç§’
        assert elapsed_time < 10.0

    def _create_graph_with_size(self, num_nodes):
        """åˆ›å»ºæŒ‡å®šè§„æ¨¡çš„ä¾èµ–å›¾"""
        from src.core.graph.graph import DependencyGraph
        from src.core.graph.node import Node, NodeType
        from src.core.graph.edge import Edge, EdgeType

        graph = DependencyGraph()

        # æ·»åŠ èŠ‚ç‚¹
        for i in range(num_nodes):
            node = Node(f"NODE-{i}", NodeType.REQUIREMENT, "test.md", i)
            graph.add_node(node)

        # æ·»åŠ è¾¹ï¼ˆåˆ›å»ºé“¾å¼ä¾èµ–ï¼‰
        for i in range(num_nodes - 1):
            edge = Edge(f"NODE-{i+1}", f"NODE-{i}", EdgeType.IMPLEMENTS, "test.md", i)
            graph.add_edge(edge)

        return graph
```

---

### **4.3 ä¸€è‡´æ€§æ£€æŸ¥æ€§èƒ½æµ‹è¯•**

**[ID: TD-PERF-CONSISTENCY-001] [Tests-for: RD-NFR-2.2]**

```python
# tests/performance/test_consistency_performance.py

import pytest
import time

class TestConsistencyPerformance:
    """ä¸€è‡´æ€§æ£€æŸ¥æ€§èƒ½æµ‹è¯•"""

    def test_single_requirement_check_time(self, sample_project, mocker):
        """æµ‹è¯•å•éœ€æ±‚æ£€æŸ¥æ—¶é—´ï¼ˆ< 2åˆ†é’Ÿï¼‰"""
        from click.testing import CliRunner
        from src.cli.main import cli

        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # Mock AI åç«¯ï¼ˆå¿«é€Ÿå“åº”ï¼‰
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": []}',
                tokens_input=3000,
                tokens_output=500,
                cost=0.02
            )

            # æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼ˆè®¡æ—¶ï¼‰
            start_time = time.time()
            result = runner.invoke(cli, ['check:consistency', '--scope=RD-REQ-005'])
            elapsed_time = time.time() - start_time

            # éªŒè¯ï¼š< 120 ç§’
            assert elapsed_time < 120.0

    def test_module_level_check_time(self, sample_project, mocker):
        """æµ‹è¯•æ¨¡å—çº§æ£€æŸ¥æ—¶é—´ï¼ˆ< 2åˆ†é’Ÿï¼‰"""
        from click.testing import CliRunner
        from src.cli.main import cli

        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": []}',
                tokens_input=15000,
                tokens_output=1000,
                cost=0.05
            )

            # æ‰§è¡Œæ£€æŸ¥ï¼ˆè®¡æ—¶ï¼‰
            start_time = time.time()
            result = runner.invoke(cli, ['check:consistency', '--scope=AuthModule'])
            elapsed_time = time.time() - start_time

            # éªŒè¯ï¼š< 120 ç§’
            assert elapsed_time < 120.0
```

---

## **äº”ã€æˆæœ¬æµ‹è¯• (Cost Tests)**

### **5.1 AI è°ƒç”¨æˆæœ¬æµ‹è¯•**

**[ID: TD-COST-001] [Tests-for: RD-NFR-6.1]**

```python
# tests/cost/test_ai_cost.py

import pytest

class TestAICost:
    """AI è°ƒç”¨æˆæœ¬æµ‹è¯•"""

    def test_impact_analysis_zero_cost(self, sample_project):
        """æµ‹è¯•å½±å“åˆ†ææˆæœ¬ï¼ˆåº”ä¸º $0ï¼‰"""
        from click.testing import CliRunner
        from src.cli.main import cli

        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # æ‰§è¡Œå½±å“åˆ†æ
            result = runner.invoke(cli, ['analyze:impact', '--changed=docs/RD.md'])

            # éªŒè¯ï¼šä¸åº”è¯¥æœ‰ AI è°ƒç”¨æˆæœ¬
            # ï¼ˆå½±å“åˆ†ææ˜¯çº¯å›¾æŸ¥è¯¢ï¼Œä¸è°ƒç”¨ AIï¼‰
            import json
            state_file = Path(".specgov/state.json")
            if state_file.exists():
                with open(state_file) as f:
                    state = json.load(f)
                    # æˆæœ¬åº”è¯¥ä¸º 0
                    assert state.get('total_cost', 0) == 0

    def test_single_requirement_check_cost(self, sample_project, mocker):
        """æµ‹è¯•å•éœ€æ±‚æ£€æŸ¥æˆæœ¬ï¼ˆ< $0.02ï¼‰"""
        from click.testing import CliRunner
        from src.cli.main import cli

        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": []}',
                tokens_input=3000,
                tokens_output=500,
                cost=0.015  # æ¨¡æ‹Ÿæˆæœ¬
            )

            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # æ‰§è¡Œæ£€æŸ¥
            result = runner.invoke(cli, ['check:consistency', '--scope=RD-REQ-005'])

            # éªŒè¯æˆæœ¬
            assert mock_backend.return_value.cost < 0.02

    def test_module_level_check_cost(self, sample_project, mocker):
        """æµ‹è¯•æ¨¡å—çº§æ£€æŸ¥æˆæœ¬ï¼ˆ< $0.05ï¼‰"""
        from click.testing import CliRunner
        from src.cli.main import cli

        runner = CliRunner()

        with runner.isolated_filesystem(temp_dir=sample_project):
            # Mock AI åç«¯
            mock_backend = mocker.patch('src.ai.claude_code.ClaudeCodeBackend.generate')
            mock_backend.return_value = mocker.Mock(
                content='{"inconsistencies": []}',
                tokens_input=15000,
                tokens_output=1000,
                cost=0.045  # æ¨¡æ‹Ÿæˆæœ¬
            )

            # æ„å»ºç´¢å¼•
            runner.invoke(cli, ['index:build'])

            # æ‰§è¡Œæ£€æŸ¥
            result = runner.invoke(cli, ['check:consistency', '--scope=AuthModule'])

            # éªŒè¯æˆæœ¬
            assert mock_backend.return_value.cost < 0.05
```

---

## **å…­ã€æµ‹è¯•æ•°æ®å‡†å¤‡ (Test Data Preparation)**

### **6.1 æµ‹è¯•å¤¹å…· (Fixtures)**

**[ID: TD-FIXTURE-001]**

```python
# tests/conftest.py

import pytest
from pathlib import Path
import tempfile
import shutil

@pytest.fixture
def sample_project(tmp_path):
    """åˆ›å»ºç¤ºä¾‹é¡¹ç›®"""
    project_dir = tmp_path / "sample_project"
    project_dir.mkdir()

    # åˆ›å»ºç›®å½•ç»“æ„
    (project_dir / "docs").mkdir()
    (project_dir / "src").mkdir()
    (project_dir / ".specgov").mkdir()

    # åˆ›å»º RD æ–‡æ¡£
    rd_content = """
# Requirements Document

## OAuth2 ç™»å½•éœ€æ±‚
**[ID: RD-REQ-005]**

ç³»ç»Ÿéœ€æ”¯æŒ OAuth2 ç™»å½•æµç¨‹ã€‚
"""
    (project_dir / "docs" / "RD.md").write_text(rd_content)

    # åˆ›å»º PRD æ–‡æ¡£
    prd_content = """
# Product Requirements Document

## OAuth2 ç™»å½•åŠŸèƒ½
**[ID: PRD-FEAT-012]** [Implements: RD-REQ-005]

å®ç° OAuth2 ç™»å½•æµç¨‹ã€‚
"""
    (project_dir / "docs" / "PRD.md").write_text(prd_content)

    # åˆ›å»º DD æ–‡æ¡£
    dd_content = """
# Design Document

## OAuth2 API è®¾è®¡
**[ID: DD-API-008]** [Designs-for: PRD-FEAT-012]

POST /auth/oauth2/callback
"""
    (project_dir / "docs" / "DD.md").write_text(dd_content)

    # åˆ›å»ºä»£ç æ–‡ä»¶
    code_content = """
// [ID: CODE-API-008] [Implements: DD-API-008]
export class AuthController {
    async oauth2Callback(req: Request, res: Response) {
        // å®ç° OAuth2 å›è°ƒ
    }
}
"""
    (project_dir / "src" / "auth.controller.ts").write_text(code_content)

    return project_dir

@pytest.fixture
def large_sample_project(tmp_path):
    """åˆ›å»ºå¤§å‹ç¤ºä¾‹é¡¹ç›®ï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰"""
    project_dir = tmp_path / "large_project"
    project_dir.mkdir()

    # åˆ›å»ºç›®å½•
    (project_dir / "docs").mkdir()
    (project_dir / "src").mkdir()

    # ç”Ÿæˆå¤§é‡æ–‡æ¡£
    for i in range(100):
        doc_content = f"""
# Module {i}

## Requirement {i}
**[ID: RD-REQ-{i:03d}]**

Description for requirement {i}.
"""
        (project_dir / "docs" / f"module_{i}.md").write_text(doc_content)

    return project_dir

@pytest.fixture
def million_line_project(tmp_path):
    """åˆ›å»º 100 ä¸‡è¡Œä»£ç é¡¹ç›®ï¼ˆç”¨äºå‹åŠ›æµ‹è¯•ï¼‰"""
    project_dir = tmp_path / "million_line_project"
    project_dir.mkdir()

    # åˆ›å»ºç›®å½•
    (project_dir / "src").mkdir()

    # ç”Ÿæˆå¤§é‡ä»£ç æ–‡ä»¶ï¼ˆæ¯ä¸ªæ–‡ä»¶ 10,000 è¡Œï¼‰
    for i in range(100):
        code_lines = []
        for j in range(10000):
            if j % 100 == 0:
                code_lines.append(f"// [ID: CODE-{i:03d}-{j:05d}]")
            code_lines.append(f"function func_{i}_{j}() {{}}")

        code_content = "\n".join(code_lines)
        (project_dir / "src" / f"module_{i}.ts").write_text(code_content)

    return project_dir

@pytest.fixture
def inconsistent_project(tmp_path):
    """åˆ›å»ºåŒ…å«ä¸ä¸€è‡´çš„æµ‹è¯•é¡¹ç›®"""
    project_dir = tmp_path / "inconsistent_project"
    project_dir.mkdir()

    (project_dir / "docs").mkdir()
    (project_dir / "src").mkdir()

    # RD: è¦æ±‚ POST
    rd_content = """
**[ID: RD-REQ-010]**
API åº”ä½¿ç”¨ POST æ–¹æ³•åˆ›å»ºæ”¯ä»˜ã€‚
"""
    (project_dir / "docs" / "RD.md").write_text(rd_content)

    # DD: è®¾è®¡ä¸º POST
    dd_content = """
**[ID: DD-API-015]** [Implements: RD-REQ-010]
POST /payments
"""
    (project_dir / "docs" / "DD.md").write_text(dd_content)

    # Code: å®ç°ä¸º PUTï¼ˆä¸ä¸€è‡´ï¼‰
    code_content = """
// [ID: CODE-API-015] [Implements: DD-API-015]
router.put('/payments', createPayment);  // é”™è¯¯ï¼šåº”è¯¥æ˜¯ POST
"""
    (project_dir / "src" / "payment.routes.ts").write_text(code_content)

    return project_dir

@pytest.fixture
def large_dependency_graph():
    """åˆ›å»ºå¤§å‹ä¾èµ–å›¾"""
    from src.core.graph.graph import DependencyGraph
    from src.core.graph.node import Node, NodeType
    from src.core.graph.edge import Edge, EdgeType

    graph = DependencyGraph()

    # åˆ›å»º 1000 ä¸ªèŠ‚ç‚¹çš„å¤æ‚ä¾èµ–å›¾
    for i in range(1000):
        node = Node(f"NODE-{i}", NodeType.REQUIREMENT, "test.md", i)
        graph.add_node(node)

    # åˆ›å»ºå¤æ‚çš„ä¾èµ–å…³ç³»
    for i in range(999):
        edge = Edge(f"NODE-{i+1}", f"NODE-{i}", EdgeType.IMPLEMENTS, "test.md", i)
        graph.add_edge(edge)

    return graph
```

---

## **ä¸ƒã€æµ‹è¯•æ‰§è¡Œè®¡åˆ’ (Test Execution Plan)**

### **7.1 æµ‹è¯•é˜¶æ®µåˆ’åˆ†**

**[ID: TD-PLAN-001]**

| é˜¶æ®µ | æµ‹è¯•ç±»å‹ | æ‰§è¡Œæ—¶æœº | è´Ÿè´£äºº |
|------|---------|---------|--------|
| **å•å…ƒæµ‹è¯•** | æ‰€æœ‰å•å…ƒæµ‹è¯• | æ¯æ¬¡ä»£ç æäº¤å‰ | å¼€å‘å·¥ç¨‹å¸ˆ |
| **é›†æˆæµ‹è¯•** | CLI å‘½ä»¤é›†æˆæµ‹è¯• | æ¯æ—¥æ„å»º | å¼€å‘å·¥ç¨‹å¸ˆ |
| **æ€§èƒ½æµ‹è¯•** | æ€§èƒ½åŸºå‡†æµ‹è¯• | æ¯å‘¨ | æ¶æ„å¸ˆ |
| **æˆæœ¬æµ‹è¯•** | AI æˆæœ¬æµ‹è¯• | æ¯æ¬¡ AI é›†æˆå˜æ›´å | äº§å“ç»ç† |
| **ç«¯åˆ°ç«¯æµ‹è¯•** | å®Œæ•´æµç¨‹æµ‹è¯• | å‘å¸ƒå‰ | æµ‹è¯•ç»ç† |

### **7.2 æŒç»­é›†æˆé…ç½®**

**[ID: TD-PLAN-002]**

```yaml
# .github/workflows/test.yml

name: Test Suite

on: [push, pull_request]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-benchmark
      - name: Run unit tests
        run: pytest tests/unit --cov=src --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  integration-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run integration tests
        run: pytest tests/integration

  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run performance tests
        run: pytest tests/performance --benchmark-only
```

---

## **å…«ã€éªŒæ”¶æ ‡å‡† (Acceptance Criteria)**

### **8.1 åŠŸèƒ½éªŒæ”¶**

**[ID: TD-ACCEPTANCE-FUNC-001]**

| åŠŸèƒ½æ¨¡å— | éªŒæ”¶æ ‡å‡† |
|---------|---------|
| **Tag Parser** | âœ… å‡†ç¡®ç‡ â‰¥ 95%<br>âœ… æ”¯æŒæ‰€æœ‰æ ‡è®°ç±»å‹<br>âœ… å¤„ç†è¾¹ç•Œæƒ…å†µæ— å´©æºƒ |
| **Dependency Graph** | âœ… æ­£ç¡®æ„å»ºä¾èµ–å…³ç³»<br>âœ… æ£€æµ‹å¾ªç¯ä¾èµ–<br>âœ… åºåˆ—åŒ–/ååºåˆ—åŒ–æ— æŸ |
| **Context Builder** | âœ… Token é™åˆ¶å¼ºåˆ¶æ‰§è¡Œ<br>âœ… æ™ºèƒ½è£å‰ªåŠŸèƒ½æ­£å¸¸<br>âœ… ä¸Šä¸‹æ–‡æ„å»ºæ­£ç¡® |
| **State Manager** | âœ… çŠ¶æ€æŒä¹…åŒ–æ­£å¸¸<br>âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥æ­£ç¡®<br>âœ… æˆæœ¬ç»Ÿè®¡å‡†ç¡® |
| **Impact Analyzer** | âœ… å½±å“åˆ†æå‡†ç¡®<br>âœ… å“åº”æ—¶é—´ < 10 ç§’<br>âœ… é›¶ AI æˆæœ¬ |
| **Task Management** | âœ… ä¸¤å±‚ä»»åŠ¡ç»“æ„æ­£å¸¸<br>âœ… å¤æ‚åº¦æ£€æŸ¥å‡†ç¡®<br>âœ… ä»»åŠ¡åˆ†è§£å»ºè®®åˆç† |

### **8.2 æ€§èƒ½éªŒæ”¶**

**[ID: TD-ACCEPTANCE-PERF-001]**

| æ€§èƒ½æŒ‡æ ‡ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|---------|--------|---------|
| **ç´¢å¼•æ„å»ºï¼ˆ100ä¸‡è¡Œï¼‰** | < 1 åˆ†é’Ÿ | âœ… å¿…é¡»æ»¡è¶³ |
| **å¢é‡ç´¢å¼•æ›´æ–°** | < 5 ç§’ | âœ… å¿…é¡»æ»¡è¶³ |
| **å½±å“åˆ†æ** | < 10 ç§’ | âœ… å¿…é¡»æ»¡è¶³ |
| **å•éœ€æ±‚ä¸€è‡´æ€§æ£€æŸ¥** | < 2 åˆ†é’Ÿ | âœ… å¿…é¡»æ»¡è¶³ |
| **æ¨¡å—çº§ä¸€è‡´æ€§æ£€æŸ¥** | < 2 åˆ†é’Ÿ | âœ… å¿…é¡»æ»¡è¶³ |
| **å…¨é¡¹ç›®ä¸€è‡´æ€§æ£€æŸ¥** | < 10 åˆ†é’Ÿ | âœ… å»ºè®®æ»¡è¶³ |

### **8.3 æˆæœ¬éªŒæ”¶**

**[ID: TD-ACCEPTANCE-COST-001]**

| æ“ä½œç±»å‹ | æˆæœ¬ç›®æ ‡ | éªŒæ”¶æ ‡å‡† |
|---------|---------|---------|
| **å½±å“åˆ†æ** | $0 | âœ… å¿…é¡»æ»¡è¶³ |
| **ç´¢å¼•æ„å»º** | $0 | âœ… å¿…é¡»æ»¡è¶³ |
| **å•éœ€æ±‚æ£€æŸ¥** | < $0.02 | âœ… å¿…é¡»æ»¡è¶³ |
| **æ¨¡å—çº§æ£€æŸ¥** | < $0.05 | âœ… å¿…é¡»æ»¡è¶³ |
| **å…¨é¡¹ç›®æ£€æŸ¥** | < $2.00 | âœ… å»ºè®®æ»¡è¶³ |

### **8.4 è´¨é‡éªŒæ”¶**

**[ID: TD-ACCEPTANCE-QUALITY-001]**

| è´¨é‡æŒ‡æ ‡ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† |
|---------|--------|---------|
| **ä»£ç è¦†ç›–ç‡** | â‰¥ 90% | âœ… å¿…é¡»æ»¡è¶³ |
| **åˆ†æ”¯è¦†ç›–ç‡** | â‰¥ 85% | âœ… å¿…é¡»æ»¡è¶³ |
| **ä¸ä¸€è‡´æ£€æµ‹å‡†ç¡®ç‡** | â‰¥ 85% | âœ… å¿…é¡»æ»¡è¶³ |
| **æ ‡è®°è§£æå‡†ç¡®ç‡** | â‰¥ 95% | âœ… å¿…é¡»æ»¡è¶³ |

---

## **ä¹ã€æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿ (Test Report Template)**

### **9.1 æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Š**

**[ID: TD-REPORT-001]**

```markdown
# SpecGovernor æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Š

**æµ‹è¯•æ—¥æœŸ**: YYYY-MM-DD
**æµ‹è¯•ç‰ˆæœ¬**: vX.Y.Z
**æµ‹è¯•æ‰§è¡Œäºº**: XXX

## ä¸€ã€æµ‹è¯•æ‘˜è¦

| æµ‹è¯•ç±»å‹ | æ€»è®¡ | é€šè¿‡ | å¤±è´¥ | è·³è¿‡ | é€šè¿‡ç‡ |
|---------|------|------|------|------|--------|
| å•å…ƒæµ‹è¯• | 120 | 118 | 2 | 0 | 98.3% |
| é›†æˆæµ‹è¯• | 45 | 43 | 2 | 0 | 95.6% |
| æ€§èƒ½æµ‹è¯• | 15 | 14 | 1 | 0 | 93.3% |
| æˆæœ¬æµ‹è¯• | 10 | 10 | 0 | 0 | 100% |

**æ€»ä½“é€šè¿‡ç‡**: 96.8%

## äºŒã€å¤±è´¥ç”¨ä¾‹åˆ†æ

### 2.1 å•å…ƒæµ‹è¯•å¤±è´¥

1. **test_parse_large_file_performance**
   - åŸå› ï¼šè§£ææ—¶é—´è¶…è¿‡ 1 ç§’ï¼ˆå®é™… 1.2 ç§’ï¼‰
   - å½±å“ï¼šæ€§èƒ½ä¸è¾¾æ ‡
   - ä¿®å¤è®¡åˆ’ï¼šä¼˜åŒ–è§£æç®—æ³•

### 2.2 é›†æˆæµ‹è¯•å¤±è´¥

1. **test_full_project_consistency_check**
   - åŸå› ï¼šè¶…æ—¶ï¼ˆ> 10 åˆ†é’Ÿï¼‰
   - å½±å“ï¼šå…¨é¡¹ç›®æ£€æŸ¥æ€§èƒ½ä¸è¾¾æ ‡
   - ä¿®å¤è®¡åˆ’ï¼šä¼˜åŒ–å¹¶è¡Œæ‰§è¡Œ

## ä¸‰ã€æ€§èƒ½æµ‹è¯•ç»“æœ

| æ€§èƒ½æŒ‡æ ‡ | ç›®æ ‡å€¼ | å®é™…å€¼ | çŠ¶æ€ |
|---------|--------|--------|------|
| ç´¢å¼•æ„å»º | < 60s | 52s | âœ… |
| å½±å“åˆ†æ | < 10s | 7s | âœ… |
| å•éœ€æ±‚æ£€æŸ¥ | < 120s | 95s | âœ… |

## å››ã€ä»£ç è¦†ç›–ç‡

- **æ€»ä½“è¦†ç›–ç‡**: 92.5%
- **å•å…ƒæµ‹è¯•è¦†ç›–ç‡**: 94.8%
- **é›†æˆæµ‹è¯•è¦†ç›–ç‡**: 88.2%

## äº”ã€å¾…ä¿®å¤é—®é¢˜

1. Tag Parser æ€§èƒ½ä¼˜åŒ–
2. å…¨é¡¹ç›®æ£€æŸ¥å¹¶è¡ŒåŒ–
3. è¾¹ç•Œæƒ…å†µå¤„ç†å¢å¼º

## å…­ã€ç»“è®º

æµ‹è¯•æ€»ä½“é€šè¿‡ç‡ä¸º 96.8%ï¼Œè¾¾åˆ°å‘å¸ƒæ ‡å‡†ã€‚å»ºè®®ä¿®å¤ä¸Šè¿°é—®é¢˜åè¿›è¡Œå›å½’æµ‹è¯•ã€‚
```

---

## **åã€æ€»ç»“ä¸ä¸‹ä¸€æ­¥ (Summary & Next Steps)**

### **10.1 æµ‹è¯•è¦†ç›–èŒƒå›´**

**[ID: TD-SUMMARY-001]**

æœ¬æµ‹è¯•æ–‡æ¡£å…¨é¢è¦†ç›–äº† SpecGovernor ç³»ç»Ÿçš„ï¼š

1. âœ… **å•å…ƒæµ‹è¯•**ï¼šæ‰€æœ‰æ ¸å¿ƒæ¨¡å—ï¼ˆTag Parser, Graph, Context Builder, State Manager, Task Managementï¼‰
2. âœ… **é›†æˆæµ‹è¯•**ï¼šå®Œæ•´çš„æ–‡æ¡£ç”Ÿæˆæµç¨‹ã€ç´¢å¼•æ„å»ºã€å½±å“åˆ†æã€ä¸€è‡´æ€§æ£€æŸ¥
3. âœ… **æ€§èƒ½æµ‹è¯•**ï¼šç´¢å¼•æ„å»ºã€å½±å“åˆ†æã€ä¸€è‡´æ€§æ£€æŸ¥çš„æ€§èƒ½åŸºå‡†
4. âœ… **æˆæœ¬æµ‹è¯•**ï¼šæ‰€æœ‰ AI è°ƒç”¨çš„æˆæœ¬æ§åˆ¶éªŒè¯
5. âœ… **ç«¯åˆ°ç«¯æµ‹è¯•**ï¼šRD â†’ PRD â†’ DD â†’ TD â†’ Code å®Œæ•´æµç¨‹

### **10.2 å…³é”®æµ‹è¯•ç‚¹**

**[ID: TD-SUMMARY-002]**

- ğŸ¯ **å‡†ç¡®æ€§**ï¼šæ ‡è®°è§£æå‡†ç¡®ç‡ â‰¥ 95%ï¼Œä¸ä¸€è‡´æ£€æµ‹å‡†ç¡®ç‡ â‰¥ 85%
- âš¡ **æ€§èƒ½**ï¼šç´¢å¼•æ„å»º < 1åˆ†é’Ÿï¼Œå½±å“åˆ†æ < 10ç§’ï¼Œä¸€è‡´æ€§æ£€æŸ¥ < 2åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**ï¼šå½±å“åˆ†æ $0ï¼Œå•éœ€æ±‚æ£€æŸ¥ < $0.02ï¼Œå…¨é¡¹ç›®æ£€æŸ¥ < $2
- ğŸ“Š **è´¨é‡**ï¼šä»£ç è¦†ç›–ç‡ â‰¥ 90%ï¼Œåˆ†æ”¯è¦†ç›–ç‡ â‰¥ 85%

### **10.3 ä¸‹ä¸€æ­¥å·¥ä½œ**

**[ID: TD-NEXT-001]**

1. â³ **å®ç°æµ‹è¯•æ¡†æ¶**ï¼šæ­å»º pytest æµ‹è¯•ç¯å¢ƒ
2. â³ **ç¼–å†™æµ‹è¯•æ•°æ®**ï¼šåˆ›å»ºå„ç§è§„æ¨¡çš„æµ‹è¯•é¡¹ç›®
3. â³ **æ‰§è¡ŒåŸºå‡†æµ‹è¯•**ï¼šå»ºç«‹æ€§èƒ½å’Œæˆæœ¬åŸºå‡†
4. â³ **æŒç»­é›†æˆé…ç½®**ï¼šé…ç½® GitHub Actions è‡ªåŠ¨åŒ–æµ‹è¯•
5. â³ **å¼€å§‹ä»£ç å®ç°**ï¼šåŸºäº DD å®ç°æ ¸å¿ƒæ¨¡å—

---

**æµ‹è¯•æ–‡æ¡£ç»“æŸ (End of Test Document)**
